{"config":{"lang":["en"],"separator":"[\\s\\u200b\\u3000\\-\u3001\u3002\uff0c\uff0e\uff1f\uff01\uff1b]+","pipeline":["stemmer"]},"docs":[{"location":"","title":"Pytorch\u5168\u6808\u5f00\u53d1\u53ca\u9879\u76ee\u5b9e\u6218","text":"<p>pytorch\u6559\u7a0b\uff0c\u5728pytorch-deep-learning\u9879\u76ee\u7684\u57fa\u7840\u4e0a\u8fdb\u884c\u7ffb\u8bd1\u548c\u5b8c\u5584</p>"},{"location":"exercises/answers/00_pytorch_fundamentals_exercise_solutions/","title":"00. PyTorch Fundamentals Exercise Solutions","text":"In\u00a0[1]: Copied! <pre># No code solution (reading)\n</pre> # No code solution (reading) In\u00a0[2]: Copied! <pre># Import torch\nimport torch \n\n# Create random tensor\nX = torch.rand(size=(7, 7))\nX, X.shape\n</pre> # Import torch import torch   # Create random tensor X = torch.rand(size=(7, 7)) X, X.shape Out[2]: <pre>(tensor([[0.5656, 0.4012, 0.1987, 0.2464, 0.6861, 0.4953, 0.3433],\n         [0.0032, 0.0228, 0.9020, 0.1267, 0.8009, 0.5274, 0.7453],\n         [0.9123, 0.8138, 0.1667, 0.5998, 0.4657, 0.4473, 0.8367],\n         [0.5302, 0.2213, 0.4747, 0.6485, 0.4770, 0.8675, 0.3054],\n         [0.4226, 0.1398, 0.4495, 0.6974, 0.1808, 0.5872, 0.6931],\n         [0.2153, 0.7517, 0.3505, 0.3815, 0.3244, 0.2511, 0.4269],\n         [0.1158, 0.6696, 0.3733, 0.2633, 0.4102, 0.1101, 0.1613]]),\n torch.Size([7, 7]))</pre> In\u00a0[3]: Copied! <pre># Create another random tensor\nY = torch.rand(size=(1, 7))\n# Z = torch.matmul(X, Y) # will error because of shape issues\nZ = torch.matmul(X, Y.T) # no error because of transpose\nZ, Z.shape\n</pre> # Create another random tensor Y = torch.rand(size=(1, 7)) # Z = torch.matmul(X, Y) # will error because of shape issues Z = torch.matmul(X, Y.T) # no error because of transpose Z, Z.shape Out[3]: <pre>(tensor([[1.0888],\n         [1.7506],\n         [1.8468],\n         [1.7496],\n         [1.9022],\n         [1.2684],\n         [0.8617]]), torch.Size([7, 1]))</pre> In\u00a0[4]: Copied! <pre># Set manual seed\ntorch.manual_seed(0)\n\n# Create two random tensors\nX = torch.rand(size=(7, 7))\nY = torch.rand(size=(1, 7))\n\n# Matrix multiply tensors\nZ = torch.matmul(X, Y.T)\nZ, Z.shape\n</pre> # Set manual seed torch.manual_seed(0)  # Create two random tensors X = torch.rand(size=(7, 7)) Y = torch.rand(size=(1, 7))  # Matrix multiply tensors Z = torch.matmul(X, Y.T) Z, Z.shape Out[4]: <pre>(tensor([[1.8542],\n         [1.9611],\n         [2.2884],\n         [3.0481],\n         [1.7067],\n         [2.5290],\n         [1.7989]]), torch.Size([7, 1]))</pre> In\u00a0[5]: Copied! <pre># Set random seed on the GPU\ntorch.cuda.manual_seed(1234)\n</pre> # Set random seed on the GPU torch.cuda.manual_seed(1234) In\u00a0[6]: Copied! <pre># Set random seed\ntorch.manual_seed(1234)\n\n# Check for access to GPU\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Device: {device}\")\n\n# Create two random tensors on GPU\ntensor_A = torch.rand(size=(2,3)).to(device)\ntensor_B = torch.rand(size=(2,3)).to(device)\ntensor_A, tensor_B\n</pre> # Set random seed torch.manual_seed(1234)  # Check for access to GPU device = \"cuda\" if torch.cuda.is_available() else \"cpu\" print(f\"Device: {device}\")  # Create two random tensors on GPU tensor_A = torch.rand(size=(2,3)).to(device) tensor_B = torch.rand(size=(2,3)).to(device) tensor_A, tensor_B <pre>Device: cuda\n</pre> Out[6]: <pre>(tensor([[0.0290, 0.4019, 0.2598],\n         [0.3666, 0.0583, 0.7006]], device='cuda:0'),\n tensor([[0.0518, 0.4681, 0.6738],\n         [0.3315, 0.7837, 0.5631]], device='cuda:0'))</pre> In\u00a0[7]: Copied! <pre># Perform matmul on tensor_A and tensor_B\n# tensor_C = torch.matmul(tensor_A, tensor_B) # won't work because of shape error\ntensor_C = torch.matmul(tensor_A, tensor_B.T)\ntensor_C, tensor_C.shape\n</pre> # Perform matmul on tensor_A and tensor_B # tensor_C = torch.matmul(tensor_A, tensor_B) # won't work because of shape error tensor_C = torch.matmul(tensor_A, tensor_B.T) tensor_C, tensor_C.shape Out[7]: <pre>(tensor([[0.3647, 0.4709],\n         [0.5184, 0.5617]], device='cuda:0'), torch.Size([2, 2]))</pre> In\u00a0[8]: Copied! <pre># Find max\nmax = torch.max(tensor_C)\n\n# Find min\nmin = torch.min(tensor_C)\nmax, min\n</pre> # Find max max = torch.max(tensor_C)  # Find min min = torch.min(tensor_C) max, min Out[8]: <pre>(tensor(0.5617, device='cuda:0'), tensor(0.3647, device='cuda:0'))</pre> In\u00a0[9]: Copied! <pre># Find arg max\narg_max = torch.argmax(tensor_C)\n\n# Find arg min\narg_min = torch.argmin(tensor_C)\narg_max, arg_min\n</pre> # Find arg max arg_max = torch.argmax(tensor_C)  # Find arg min arg_min = torch.argmin(tensor_C) arg_max, arg_min Out[9]: <pre>(tensor(3, device='cuda:0'), tensor(0, device='cuda:0'))</pre> In\u00a0[10]: Copied! <pre># Set seed\ntorch.manual_seed(7)\n\n# Create random tensor\ntensor_D = torch.rand(size=(1, 1, 1, 10))\n\n# Remove single dimensions\ntensor_E = tensor_D.squeeze()\n\n# Print out tensors\nprint(tensor_D, tensor_D.shape)\nprint(tensor_E, tensor_E.shape)\n</pre> # Set seed torch.manual_seed(7)  # Create random tensor tensor_D = torch.rand(size=(1, 1, 1, 10))  # Remove single dimensions tensor_E = tensor_D.squeeze()  # Print out tensors print(tensor_D, tensor_D.shape) print(tensor_E, tensor_E.shape) <pre>tensor([[[[0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297,\n           0.3653, 0.8513]]]]) torch.Size([1, 1, 1, 10])\ntensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297, 0.3653,\n        0.8513]) torch.Size([10])\n</pre>"},{"location":"exercises/answers/00_pytorch_fundamentals_exercise_solutions/#00-pytorch-fundamentals-exercise-solutions","title":"00. PyTorch Fundamentals Exercise Solutions\u00b6","text":""},{"location":"exercises/answers/00_pytorch_fundamentals_exercise_solutions/#1-documentation-reading","title":"1. Documentation reading\u00b6","text":"<p>A big part of deep learning (and learning to code in general) is getting familiar with the documentation of a certain framework you're using. We'll be using the PyTorch documentation a lot throughout the rest of this course. So I'd recommend spending 10-minutes reading the following (it's okay if you don't get some things for now, the focus is not yet full understanding, it's awareness):</p> <ul> <li>The documentation on <code>torch.Tensor</code>.</li> <li>The documentation on <code>torch.cuda</code>.</li> </ul>"},{"location":"exercises/answers/00_pytorch_fundamentals_exercise_solutions/#2-create-a-random-tensor-with-shape-7-7","title":"2. Create a random tensor with shape <code>(7, 7)</code>.\u00b6","text":""},{"location":"exercises/answers/00_pytorch_fundamentals_exercise_solutions/#3-perform-a-matrix-multiplication-on-the-tensor-from-2-with-another-random-tensor-with-shape-1-7-hint-you-may-have-to-transpose-the-second-tensor","title":"3. Perform a matrix multiplication on the tensor from 2 with another random tensor with shape <code>(1, 7)</code> (hint: you may have to transpose the second tensor).\u00b6","text":""},{"location":"exercises/answers/00_pytorch_fundamentals_exercise_solutions/#4-set-the-random-seed-to-0-and-do-2-3-over-again","title":"4. Set the random seed to <code>0</code> and do 2 &amp; 3 over again.\u00b6","text":"<p>The output should be:</p> <pre><code>(tensor([[1.8542],\n         [1.9611],\n         [2.2884],\n         [3.0481],\n         [1.7067],\n         [2.5290],\n         [1.7989]]), torch.Size([7, 1]))\n</code></pre>"},{"location":"exercises/answers/00_pytorch_fundamentals_exercise_solutions/#5-speaking-of-random-seeds-we-saw-how-to-set-it-with-torchmanual_seed-but-is-there-a-gpu-equivalent-hint-youll-need-to-look-into-the-documentation-for-torchcuda-for-this-one","title":"5. Speaking of random seeds, we saw how to set it with <code>torch.manual_seed()</code> but is there a GPU equivalent? (hint: you'll need to look into the documentation for <code>torch.cuda</code> for this one)\u00b6","text":"<ul> <li>If there is, set the GPU random seed to <code>1234</code>.</li> </ul>"},{"location":"exercises/answers/00_pytorch_fundamentals_exercise_solutions/#6-create-two-random-tensors-of-shape-2-3-and-send-them-both-to-the-gpu-youll-need-access-to-a-gpu-for-this-set-torchmanual_seed1234-when-creating-the-tensors-this-doesnt-have-to-be-the-gpu-random-seed-the-output-should-be-something-like","title":"6. Create two random tensors of shape <code>(2, 3)</code> and send them both to the GPU (you'll need access to a GPU for this). Set <code>torch.manual_seed(1234)</code> when creating the tensors (this doesn't have to be the GPU random seed). The output should be something like:\u00b6","text":"<pre><code>Device: cuda\n(tensor([[0.0290, 0.4019, 0.2598],\n         [0.3666, 0.0583, 0.7006]], device='cuda:0'),\n tensor([[0.0518, 0.4681, 0.6738],\n         [0.3315, 0.7837, 0.5631]], device='cuda:0'))\n</code></pre>"},{"location":"exercises/answers/00_pytorch_fundamentals_exercise_solutions/#7-perform-a-matrix-multiplication-on-the-tensors-you-created-in-6-again-you-may-have-to-adjust-the-shapes-of-one-of-the-tensors","title":"7. Perform a matrix multiplication on the tensors you created in 6 (again, you may have to adjust the shapes of one of the tensors).\u00b6","text":"<p>The output should look like:</p> <pre><code>(tensor([[0.3647, 0.4709],\n         [0.5184, 0.5617]], device='cuda:0'), torch.Size([2, 2]))\n</code></pre>"},{"location":"exercises/answers/00_pytorch_fundamentals_exercise_solutions/#8-find-the-maximum-and-minimum-values-of-the-output-of-7","title":"8. Find the maximum and minimum values of the output of 7.\u00b6","text":""},{"location":"exercises/answers/00_pytorch_fundamentals_exercise_solutions/#9-find-the-maximum-and-minimum-index-values-of-the-output-of-7","title":"9. Find the maximum and minimum index values of the output of 7.\u00b6","text":""},{"location":"exercises/answers/00_pytorch_fundamentals_exercise_solutions/#10-make-a-random-tensor-with-shape-1-1-1-10-and-then-create-a-new-tensor-with-all-the-1-dimensions-removed-to-be-left-with-a-tensor-of-shape-10-set-the-seed-to-7-when-you-create-it-and-print-out-the-first-tensor-and-its-shape-as-well-as-the-second-tensor-and-its-shape","title":"10. Make a random tensor with shape <code>(1, 1, 1, 10)</code> and then create a new tensor with all the <code>1</code> dimensions removed to be left with a tensor of shape <code>(10)</code>. Set the seed to <code>7</code> when you create it and print out the first tensor and it's shape as well as the second tensor and it's shape.\u00b6","text":"<p>The output should look like:</p> <pre><code>tensor([[[[0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297,\n           0.3653, 0.8513]]]]) torch.Size([1, 1, 1, 10])\ntensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297, 0.3653,\n        0.8513]) torch.Size([10])\n</code></pre>"},{"location":"exercises/questions/00_pytorch_fundamentals_exercises/","title":"00. PyTorch Fundamentals Exercises","text":"In\u00a0[1]: Copied! <pre># No code solution (reading)\n</pre> # No code solution (reading) In\u00a0[2]: Copied! <pre># Import torch\n\n\n# Create random tensor\n</pre> # Import torch   # Create random tensor  In\u00a0[3]: Copied! <pre># Create another random tensor\n\n# Perform matrix multiplication\n</pre> # Create another random tensor  # Perform matrix multiplication   In\u00a0[4]: Copied! <pre># Set manual seed\n\n\n# Create two random tensors\n\n\n# Matrix multiply tensors\n</pre> # Set manual seed   # Create two random tensors   # Matrix multiply tensors  In\u00a0[5]: Copied! <pre># Set random seed on the GPU\n</pre> # Set random seed on the GPU  In\u00a0[6]: Copied! <pre># Set random seed\n\n\n# Check for access to GPU\n\n# Create two random tensors on GPU\n</pre> # Set random seed   # Check for access to GPU  # Create two random tensors on GPU  In\u00a0[7]: Copied! <pre># Perform matmul on tensor_A and tensor_B\n</pre> # Perform matmul on tensor_A and tensor_B  In\u00a0[8]: Copied! <pre># Find max\n\n# Find min\n</pre> # Find max  # Find min  In\u00a0[9]: Copied! <pre># Find arg max\n\n\n# Find arg min\n</pre> # Find arg max   # Find arg min  In\u00a0[10]: Copied! <pre># Set seed\n\n\n# Create random tensor\n\n\n# Remove single dimensions\n\n\n# Print out tensors and their shapes\n</pre> # Set seed   # Create random tensor   # Remove single dimensions   # Print out tensors and their shapes"},{"location":"exercises/questions/00_pytorch_fundamentals_exercises/#00-pytorch-fundamentals-exercises","title":"00. PyTorch Fundamentals Exercises\u00b6","text":""},{"location":"exercises/questions/00_pytorch_fundamentals_exercises/#1-documentation-reading","title":"1. Documentation reading\u00b6","text":"<p>A big part of deep learning (and learning to code in general) is getting familiar with the documentation of a certain framework you're using. We'll be using the PyTorch documentation a lot throughout the rest of this course. So I'd recommend spending 10-minutes reading the following (it's okay if you don't get some things for now, the focus is not yet full understanding, it's awareness):</p> <ul> <li>The documentation on <code>torch.Tensor</code>.</li> <li>The documentation on <code>torch.cuda</code>.</li> </ul>"},{"location":"exercises/questions/00_pytorch_fundamentals_exercises/#2-create-a-random-tensor-with-shape-7-7","title":"2. Create a random tensor with shape <code>(7, 7)</code>.\u00b6","text":""},{"location":"exercises/questions/00_pytorch_fundamentals_exercises/#3-perform-a-matrix-multiplication-on-the-tensor-from-2-with-another-random-tensor-with-shape-1-7-hint-you-may-have-to-transpose-the-second-tensor","title":"3. Perform a matrix multiplication on the tensor from 2 with another random tensor with shape <code>(1, 7)</code> (hint: you may have to transpose the second tensor).\u00b6","text":""},{"location":"exercises/questions/00_pytorch_fundamentals_exercises/#4-set-the-random-seed-to-0-and-do-2-3-over-again","title":"4. Set the random seed to <code>0</code> and do 2 &amp; 3 over again.\u00b6","text":"<p>The output should be:</p> <pre><code>(tensor([[1.8542],\n         [1.9611],\n         [2.2884],\n         [3.0481],\n         [1.7067],\n         [2.5290],\n         [1.7989]]), torch.Size([7, 1]))\n</code></pre>"},{"location":"exercises/questions/00_pytorch_fundamentals_exercises/#5-speaking-of-random-seeds-we-saw-how-to-set-it-with-torchmanual_seed-but-is-there-a-gpu-equivalent-hint-youll-need-to-look-into-the-documentation-for-torchcuda-for-this-one","title":"5. Speaking of random seeds, we saw how to set it with <code>torch.manual_seed()</code> but is there a GPU equivalent? (hint: you'll need to look into the documentation for <code>torch.cuda</code> for this one)\u00b6","text":"<ul> <li>If there is, set the GPU random seed to <code>1234</code>.</li> </ul>"},{"location":"exercises/questions/00_pytorch_fundamentals_exercises/#6-create-two-random-tensors-of-shape-2-3-and-send-them-both-to-the-gpu-youll-need-access-to-a-gpu-for-this-set-torchmanual_seed1234-when-creating-the-tensors-this-doesnt-have-to-be-the-gpu-random-seed-the-output-should-be-something-like","title":"6. Create two random tensors of shape <code>(2, 3)</code> and send them both to the GPU (you'll need access to a GPU for this). Set <code>torch.manual_seed(1234)</code> when creating the tensors (this doesn't have to be the GPU random seed). The output should be something like:\u00b6","text":"<pre><code>Device: cuda\n(tensor([[0.0290, 0.4019, 0.2598],\n         [0.3666, 0.0583, 0.7006]], device='cuda:0'),\n tensor([[0.0518, 0.4681, 0.6738],\n         [0.3315, 0.7837, 0.5631]], device='cuda:0'))\n</code></pre>"},{"location":"exercises/questions/00_pytorch_fundamentals_exercises/#7-perform-a-matrix-multiplication-on-the-tensors-you-created-in-6-again-you-may-have-to-adjust-the-shapes-of-one-of-the-tensors","title":"7. Perform a matrix multiplication on the tensors you created in 6 (again, you may have to adjust the shapes of one of the tensors).\u00b6","text":"<p>The output should look like:</p> <pre><code>(tensor([[0.3647, 0.4709],\n         [0.5184, 0.5617]], device='cuda:0'), torch.Size([2, 2]))\n</code></pre>"},{"location":"exercises/questions/00_pytorch_fundamentals_exercises/#8-find-the-maximum-and-minimum-values-of-the-output-of-7","title":"8. Find the maximum and minimum values of the output of 7.\u00b6","text":""},{"location":"exercises/questions/00_pytorch_fundamentals_exercises/#9-find-the-maximum-and-minimum-index-values-of-the-output-of-7","title":"9. Find the maximum and minimum index values of the output of 7.\u00b6","text":""},{"location":"exercises/questions/00_pytorch_fundamentals_exercises/#10-make-a-random-tensor-with-shape-1-1-1-10-and-then-create-a-new-tensor-with-all-the-1-dimensions-removed-to-be-left-with-a-tensor-of-shape-10-set-the-seed-to-7-when-you-create-it-and-print-out-the-first-tensor-and-its-shape-as-well-as-the-second-tensor-and-its-shape","title":"10. Make a random tensor with shape <code>(1, 1, 1, 10)</code> and then create a new tensor with all the <code>1</code> dimensions removed to be left with a tensor of shape <code>(10)</code>. Set the seed to <code>7</code> when you create it and print out the first tensor and it's shape as well as the second tensor and it's shape.\u00b6","text":"<p>The output should look like:</p> <pre><code>tensor([[[[0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297,\n           0.3653, 0.8513]]]]) torch.Size([1, 1, 1, 10])\ntensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297, 0.3653,\n        0.8513]) torch.Size([10])\n</code></pre>"},{"location":"tutorials/00_pytorch_fundamentals/","title":"0 \u57fa\u7840","text":""},{"location":"tutorials/00_pytorch_fundamentals/#pytorch","title":"\u4ec0\u4e48\u662f PyTorch\uff1f","text":"<p>PyTorch \u662f\u4e00\u4e2a\u5f00\u6e90\u7684\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u3002</p>"},{"location":"tutorials/00_pytorch_fundamentals/#pytorch_1","title":"PyTorch \u53ef\u7528\u4e8e\u4ec0\u4e48\uff1f","text":"<p>PyTorch \u5141\u8bb8\u60a8\u4f7f\u7528 Python \u4ee3\u7801\u64cd\u4f5c\u548c\u5904\u7406\u6570\u636e\uff0c\u7f16\u5199\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u3002</p>"},{"location":"tutorials/00_pytorch_fundamentals/#pytorch_2","title":"\u8c01\u5728\u4f7f\u7528 PyTorch\uff1f","text":"<p>\u8bb8\u591a\u4e16\u754c\u4e0a\u6700\u5927\u7684\u6280\u672f\u516c\u53f8\uff0c\u5982 Meta\uff08Facebook\uff09\u3001Tesla \u548c Microsoft\uff0c\u4ee5\u53ca\u4eba\u5de5\u667a\u80fd\u7814\u7a76\u516c\u53f8\uff0c\u5982 OpenAI \u4f7f\u7528 PyTorch \u6765\u63a8\u52a8\u7814\u7a76\u5e76\u5c06\u673a\u5668\u5b66\u4e60\u5f15\u5165\u4ed6\u4eec\u7684\u4ea7\u54c1\u3002</p> <p></p> <p>\u4f8b\u5982\uff0c\u7279\u65af\u62c9\u7684\u4eba\u5de5\u667a\u80fd\u8d1f\u8d23\u4eba Andrej Karpathy \u66fe\u591a\u6b21\u53d1\u8868\u6f14\u8bb2\uff08PyTorch DevCon 2019\u3001\u7279\u65af\u62c9 AI Day 2021\uff09\uff0c\u4ecb\u7ecd\u4e86\u7279\u65af\u62c9\u5982\u4f55\u4f7f\u7528 PyTorch \u6765\u9a71\u52a8\u4ed6\u4eec\u7684\u81ea\u52a8\u9a7e\u9a76\u8ba1\u7b97\u673a\u89c6\u89c9\u6a21\u578b\u3002</p> <p>PyTorch \u4e5f\u5728\u5176\u4ed6\u884c\u4e1a\u4e2d\u4f7f\u7528\uff0c\u6bd4\u5982\u5728\u519c\u4e1a\u4e2d\u7528\u4e8e \u9a71\u52a8\u62d6\u62c9\u673a\u4e0a\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\u3002</p>"},{"location":"tutorials/00_pytorch_fundamentals/#pytorch_3","title":"\u4e3a\u4ec0\u4e48\u4f7f\u7528 PyTorch\uff1f","text":"<p>\u673a\u5668\u5b66\u4e60\u7814\u7a76\u4eba\u5458\u559c\u6b22\u4f7f\u7528 PyTorch\u3002\u622a\u81f3 2022 \u5e74 2 \u6708\uff0cPyTorch \u662f Papers With Code \u4e0a\u4f7f\u7528\u6700\u591a\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u4e2a\u7528\u4e8e\u8ddf\u8e2a\u673a\u5668\u5b66\u4e60\u7814\u7a76\u8bba\u6587\u548c\u9644\u5e26\u4ee3\u7801\u5b58\u50a8\u5e93\u7684\u7f51\u7ad9\u3002</p> <p>PyTorch \u8fd8\u80fd\u591f\u5728\u5e55\u540e\u5904\u7406\u8bb8\u591a\u4e8b\u60c5\uff0c\u5982 GPU \u52a0\u901f\uff08\u4f7f\u60a8\u7684\u4ee3\u7801\u8fd0\u884c\u66f4\u5feb\uff09\u3002</p> <p>\u56e0\u6b64\uff0c\u60a8\u53ef\u4ee5\u4e13\u6ce8\u4e8e\u5904\u7406\u6570\u636e\u548c\u7f16\u5199\u7b97\u6cd5\uff0c\u800c PyTorch \u5c06\u786e\u4fdd\u5b83\u8fd0\u884c\u5f97\u5f88\u5feb\u3002</p> <p>\u5982\u679c\u50cf\u7279\u65af\u62c9\u548c Meta\uff08Facebook\uff09\u8fd9\u6837\u7684\u516c\u53f8\u4f7f\u7528\u5b83\u6765\u6784\u5efa\u90e8\u7f72\u5728\u6570\u767e\u4e2a\u5e94\u7528\u7a0b\u5e8f\u4e0a\u3001\u9a7e\u9a76\u6570\u5343\u8f86\u6c7d\u8f66\u5e76\u5411\u6570\u5341\u4ebf\u4eba\u63d0\u4f9b\u5185\u5bb9\u7684\u6a21\u578b\uff0c\u90a3\u4e48\u5b83\u5728\u5f00\u53d1\u65b9\u9762\u663e\u7136\u4e5f\u662f\u6709\u80fd\u529b\u7684\u3002</p>"},{"location":"tutorials/00_pytorch_fundamentals/#_1","title":"\u8fd9\u4e00\u7ae0\u5185\u5bb9","text":"<p>\u8bb2\u89e3\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u7684\u57fa\u672c\u6784\u5efa\u5757\uff0c\u5373\u5f20\u91cf\u3002</p> <p>\u5177\u4f53\u6765\u8bf4\uff0c\u5c06\u6db5\u76d6\u4ee5\u4e0b\u5185\u5bb9\uff1a</p> \u4e3b\u9898 \u5185\u5bb9 \u5f20\u91cf\u7b80\u4ecb \u5f20\u91cf\u662f\u6240\u6709\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u7684\u57fa\u672c\u6784\u5efa\u5757\u3002 \u521b\u5efa\u5f20\u91cf \u5f20\u91cf\u53ef\u4ee5\u8868\u793a\u51e0\u4e4e\u4efb\u4f55\u7c7b\u578b\u7684\u6570\u636e\uff08\u56fe\u50cf\u3001\u5355\u8bcd\u3001\u6570\u5b57\u8868\u683c\uff09\u3002 \u4ece\u5f20\u91cf\u4e2d\u83b7\u53d6\u4fe1\u606f \u5982\u679c\u60a8\u53ef\u4ee5\u5c06\u4fe1\u606f\u653e\u5165\u5f20\u91cf\uff0c\u90a3\u4e48\u60a8\u4e5f\u4f1a\u60f3\u8981\u5c06\u5b83\u53d6\u51fa\u3002 \u64cd\u4f5c\u5f20\u91cf \u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff08\u5982\u795e\u7ecf\u7f51\u7edc\uff09\u6d89\u53ca\u4ee5\u8bb8\u591a\u4e0d\u540c\u7684\u65b9\u5f0f\u64cd\u4f5c\u5f20\u91cf\uff0c\u5982\u52a0\u6cd5\u3001\u4e58\u6cd5\u3001\u7ec4\u5408\u7b49\u3002 \u5904\u7406\u5f20\u91cf\u5f62\u72b6 \u673a\u5668\u5b66\u4e60\u4e2d\u6700\u5e38\u89c1\u7684\u95ee\u9898\u4e4b\u4e00\u662f\u5904\u7406\u5f62\u72b6\u4e0d\u5339\u914d\uff08\u5c1d\u8bd5\u5c06\u9519\u8bef\u5f62\u72b6\u7684\u5f20\u91cf\u4e0e\u5176\u4ed6\u5f20\u91cf\u6df7\u5408\uff09\u3002 \u5728\u5f20\u91cf\u4e0a\u8fdb\u884c\u7d22\u5f15 \u5982\u679c\u60a8\u5df2\u7ecf\u5bf9 Python \u5217\u8868\u6216 NumPy \u6570\u7ec4\u8fdb\u884c\u4e86\u7d22\u5f15\uff0c\u90a3\u4e48\u4e0e\u5f20\u91cf\u975e\u5e38\u76f8\u4f3c\uff0c\u53ea\u662f\u5b83\u4eec\u53ef\u4ee5\u5177\u6709\u66f4\u591a\u7684\u7ef4\u5ea6\u3002 \u6df7\u5408\u4f7f\u7528 PyTorch \u5f20\u91cf\u548c NumPy PyTorch \u5904\u7406\u5f20\u91cf\uff08<code>torch.Tensor</code>\uff09\uff0cNumPy \u559c\u6b22\u6570\u7ec4\uff08<code>np.ndarray</code>\uff09\uff0c\u6709\u65f6\u60a8\u4f1a\u5e0c\u671b\u6df7\u5408\u548c\u5339\u914d\u5b83\u4eec\u3002 \u53ef\u91cd\u590d\u6027 \u673a\u5668\u5b66\u4e60\u662f\u975e\u5e38\u5b9e\u9a8c\u6027\u7684\uff0c\u56e0\u4e3a\u5b83\u4f7f\u7528\u4e86\u5927\u91cf\u7684\u968f\u673a\u6027\uff0c\u6709\u65f6\u60a8\u5e0c\u671b\u8fd9\u79cd\u968f\u673a\u6027\u4e0d\u90a3\u4e48\u968f\u673a\u3002 \u5728 GPU \u4e0a\u8fd0\u884c\u5f20\u91cf GPU\uff08\u56fe\u5f62\u5904\u7406\u5355\u5143\uff09\u53ef\u4ee5\u4f7f\u60a8\u7684\u4ee3\u7801\u8fd0\u884c\u66f4\u5feb\uff0cPyTorch \u53ef\u4ee5\u8f7b\u677e\u5730\u5728 GPU \u4e0a\u8fd0\u884c\u60a8\u7684\u4ee3\u7801\u3002"},{"location":"tutorials/00_pytorch_fundamentals/#pytorch_4","title":"\u5bfc\u5165 PyTorch","text":"<p>\u6ce8\u610f\uff1a \u5728\u8fd0\u884c\u672c\u7b14\u8bb0\u672c\u4e2d\u7684\u4efb\u4f55\u4ee3\u7801\u4e4b\u524d\uff0c\u60a8\u5e94\u8be5\u5df2\u7ecf\u5b8c\u6210\u4e86 PyTorch \u8bbe\u7f6e\u6b65\u9aa4\u3002</p> <p>\u8ba9\u6211\u4eec\u4ece\u5bfc\u5165 PyTorch \u5e76\u68c0\u67e5\u6211\u4eec\u6b63\u5728\u4f7f\u7528\u7684\u7248\u672c\u5f00\u59cb\u3002</p> <pre><code>import torch\ntorch.__version__\n</code></pre> <pre><code>'1.13.1+cu116'\n</code></pre> <p>\u592a\u68d2\u4e86\uff0c\u770b\u8d77\u6765\u6211\u4eec\u6709 PyTorch 1.10.0+\u3002</p> <p>\u8fd9\u610f\u5473\u7740\u5982\u679c\u60a8\u6b63\u5728\u5b66\u4e60\u8fd9\u4e9b\u6750\u6599\uff0c\u60a8\u5c06\u770b\u5230\u4e0e PyTorch 1.10.0+ \u6700\u517c\u5bb9\u7684\u60c5\u51b5\uff0c\u4f46\u662f\u5982\u679c\u60a8\u7684\u7248\u672c\u53f7\u8fdc\u9ad8\u4e8e\u6b64\uff0c\u60a8\u53ef\u80fd\u4f1a\u6ce8\u610f\u5230\u4e00\u4e9b\u4e0d\u4e00\u81f4\u6027\u3002</p> <p>\u5982\u679c\u60a8\u9047\u5230\u4efb\u4f55\u95ee\u9898\uff0c\u8bf7\u5728\u8bfe\u7a0b\u7684 GitHub \u8ba8\u8bba\u9875\u9762 \u4e0a\u53d1\u5e16\u3002</p>"},{"location":"tutorials/00_pytorch_fundamentals/#_2","title":"\u5f20\u91cf\u7b80\u4ecb","text":"<p>\u73b0\u5728\u6211\u4eec\u5df2\u7ecf\u5bfc\u5165\u4e86 PyTorch\uff0c\u662f\u65f6\u5019\u4e86\u89e3\u4e00\u4e0b\u5f20\u91cf\u4e86\u3002</p> <p>\u5f20\u91cf\u662f\u673a\u5668\u5b66\u4e60\u7684\u57fa\u672c\u6784\u5efa\u5757\u3002</p> <p>\u5b83\u4eec\u7684\u4efb\u52a1\u662f\u4ee5\u6570\u503c\u65b9\u5f0f\u8868\u793a\u6570\u636e\u3002</p> <p>\u4f8b\u5982\uff0c\u60a8\u53ef\u4ee5\u5c06\u56fe\u50cf\u8868\u793a\u4e3a\u5f62\u72b6\u4e3a <code>[3, 224, 224]</code> \u7684\u5f20\u91cf\uff0c\u5176\u4e2d <code>[\u989c\u8272\u901a\u9053\u6570\uff0c\u9ad8\u5ea6\uff0c\u5bbd\u5ea6]</code>\uff0c\u4f8b\u5982\u56fe\u50cf\u5177\u6709 <code>3</code> \u4e2a\u989c\u8272\u901a\u9053\uff08\u7ea2\u8272\u3001\u7eff\u8272\u3001\u84dd\u8272\uff09\uff0c\u9ad8\u5ea6\u4e3a <code>224</code> \u50cf\u7d20\uff0c\u5bbd\u5ea6\u4e3a <code>224</code> \u50cf\u7d20\u3002</p> <p></p> <p>\u5728\u5f20\u91cf\u672f\u8bed\uff08\u7528\u4e8e\u63cf\u8ff0\u5f20\u91cf\u7684\u8bed\u8a00\uff09\u4e2d\uff0c\u5f20\u91cf\u5c06\u5177\u6709\u4e09\u4e2a\u7ef4\u5ea6\uff0c\u5206\u522b\u4e3a <code>\u989c\u8272\u901a\u9053\u6570</code>\u3001<code>\u9ad8\u5ea6</code> \u548c <code>\u5bbd\u5ea6</code>\u3002</p> <p>\u4f46\u6211\u4eec\u5728\u63d0\u524d\u9884\u6d4b\u3002</p> <p>\u8ba9\u6211\u4eec\u901a\u8fc7\u7f16\u7801\u6765\u4e86\u89e3\u66f4\u591a\u5173\u4e8e\u5f20\u91cf\u7684\u77e5\u8bc6\u3002</p>"},{"location":"tutorials/00_pytorch_fundamentals/#_3","title":"\u521b\u5efa\u5f20\u91cf","text":"<p>PyTorch \u70ed\u7231\u5f20\u91cf\u3002\u4ee5\u81f3\u4e8e\u6709\u4e00\u4e2a\u5b8c\u6574\u7684\u6587\u6863\u9875\u9762\u4e13\u95e8\u4ecb\u7ecd\u4e86 <code>torch.Tensor</code> \u7c7b\u3002</p> <p>\u4f60\u7684\u7b2c\u4e00\u4e2a\u4f5c\u4e1a\u662f\u9605\u8bfb 10 \u5206\u949f\u7684 <code>torch.Tensor</code> \u6587\u6863\u3002\u4f46\u4f60\u53ef\u4ee5\u7a0d\u540e\u518d\u53bb\u9605\u8bfb\u3002</p> <p>\u8ba9\u6211\u4eec\u6765\u5199\u4ee3\u7801\u5427\u3002</p> <p>\u9996\u5148\uff0c\u6211\u4eec\u8981\u521b\u5efa\u7684\u662f\u6807\u91cf\u3002</p> <p>\u6807\u91cf\u662f\u4e00\u4e2a\u5355\u72ec\u7684\u6570\u5b57\uff0c\u5728\u5f20\u91cf\u672f\u8bed\u4e2d\uff0c\u5b83\u662f\u4e00\u4e2a\u96f6\u7ef4\u5f20\u91cf\u3002</p> <pre><code># \u6807\u91cf\nscalar = torch.tensor(7)\nscalar\n</code></pre> <pre><code>tensor(7)\n</code></pre> <p>\u770b\u5230\u4e0a\u9762\u6253\u5370\u51fa <code>tensor(7)</code> \u5417\uff1f</p> <p>\u8fd9\u610f\u5473\u7740\u867d\u7136 <code>scalar</code> \u662f\u4e00\u4e2a\u5355\u72ec\u7684\u6570\u5b57\uff0c\u4f46\u5b83\u7684\u7c7b\u578b\u662f <code>torch.Tensor</code>\u3002</p> <p>\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 <code>ndim</code> \u5c5e\u6027\u6765\u68c0\u67e5\u5f20\u91cf\u7684\u7ef4\u5ea6\u3002</p> <pre><code>scalar.ndim\n</code></pre> <pre><code>0\n</code></pre> <p>\u5982\u679c\u6211\u4eec\u60f3\u8981\u4ece\u5f20\u91cf\u4e2d\u83b7\u53d6\u6570\u5b57\uff0c\u600e\u4e48\u529e\uff1f</p> <p>\u4e5f\u5c31\u662f\u8bf4\uff0c\u5c06\u5b83\u4ece <code>torch.Tensor</code> \u8f6c\u6362\u4e3a Python \u6574\u6570\uff1f</p> <p>\u4e3a\u4e86\u505a\u5230\u8fd9\u4e00\u70b9\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 <code>item()</code> \u65b9\u6cd5\u3002</p> <pre><code># \u4ece\u5f20\u91cf\u4e2d\u83b7\u53d6 Python \u6570\u5b57\uff08\u4ec5\u9002\u7528\u4e8e\u5355\u5143\u7d20\u5f20\u91cf\uff09\nscalar.item()\n</code></pre> <pre><code>7\n</code></pre> <p>\u597d\u7684\uff0c\u73b0\u5728\u8ba9\u6211\u4eec\u770b\u4e00\u4e2a\u5411\u91cf\u3002</p> <p>\u5411\u91cf\u662f\u4e00\u4e2a\u5355\u7ef4\u5f20\u91cf\uff0c\u4f46\u53ef\u4ee5\u5305\u542b\u8bb8\u591a\u6570\u5b57\u3002</p> <p>\u4f8b\u5982\uff0c\u60a8\u53ef\u4ee5\u6709\u4e00\u4e2a\u5411\u91cf <code>[3, 2]</code> \u6765\u63cf\u8ff0\u60a8\u5bb6\u4e2d\u7684 <code>[\u5367\u5ba4\u6570\u91cf\uff0c\u6d74\u5ba4\u6570\u91cf]</code>\u3002\u6216\u8005\u60a8\u53ef\u4ee5\u6709 <code>[3, 2, 2]</code> \u6765\u63cf\u8ff0\u60a8\u5bb6\u4e2d\u7684 <code>[\u5367\u5ba4\u6570\u91cf\uff0c\u6d74\u5ba4\u6570\u91cf\uff0c\u505c\u8f66\u4f4d\u6570\u91cf]</code>\u3002</p> <p>\u8fd9\u91cc\u7684\u91cd\u8981\u8d8b\u52bf\u662f\uff0c\u5411\u91cf\u5728\u5b83\u53ef\u4ee5\u8868\u793a\u7684\u5185\u5bb9\u4e0a\u662f\u7075\u6d3b\u7684\uff08\u5f20\u91cf\u4e5f\u662f\u5982\u6b64\uff09\u3002</p> <pre><code># \u5411\u91cf\nvector = torch.tensor([7, 7])\nvector\n</code></pre> <pre><code>tensor([7, 7])\n</code></pre> <p>\u592a\u68d2\u4e86\uff0c<code>vector</code> \u73b0\u5728\u5305\u542b\u4e86\u4e24\u4e2a 7\uff0c\u8fd9\u662f\u6211\u7684\u6700\u7231\u3002</p> <p>\u4f60\u8ba4\u4e3a\u5b83\u4f1a\u6709\u591a\u5c11\u7ef4\u5ea6\u5462\uff1f</p> <pre><code># \u68c0\u67e5 vector \u7684\u7ef4\u5ea6\u6570\nvector.ndim\n</code></pre> <pre><code>1\n</code></pre> <p>\u55ef\uff0c\u8fd9\u5f88\u5947\u602a\uff0c<code>vector</code> \u5305\u542b\u4e24\u4e2a\u6570\u5b57\uff0c\u4f46\u53ea\u6709\u4e00\u4e2a\u7ef4\u5ea6\u3002</p> <p>\u6211\u544a\u8bc9\u4f60\u4e00\u4e2a\u6280\u5de7\u3002</p> <p>\u60a8\u53ef\u4ee5\u901a\u8fc7\u5f20\u91cf\u5728 PyTorch \u4e2d\u7684\u62ec\u53f7\u6570\u91cf\u6765\u5224\u65ad\u5b83\u7684\u7ef4\u5ea6\uff0c\u53ea\u9700\u8ba1\u7b97\u4e00\u4fa7\u5373\u53ef\u3002</p> <p><code>vector</code> \u6709\u591a\u5c11\u4e2a\u65b9\u62ec\u53f7\uff1f</p> <p>\u53e6\u4e00\u4e2a\u91cd\u8981\u7684\u6982\u5ff5\u662f\u5f20\u91cf\u7684 <code>shape</code> \u5c5e\u6027\u3002\u5f62\u72b6\u544a\u8bc9\u60a8\u5143\u7d20\u5728\u5176\u4e2d\u5982\u4f55\u6392\u5217\u3002</p> <p>\u8ba9\u6211\u4eec\u6765\u67e5\u770b <code>vector</code> \u7684\u5f62\u72b6\u3002</p> <pre><code># \u68c0\u67e5 vector \u7684\u5f62\u72b6\nvector.shape\n</code></pre> <pre><code>torch.Size([2])\n</code></pre> <p>\u4e0a\u9762\u7684\u8f93\u51fa\u662f <code>torch.Size([2])</code>\uff0c\u8fd9\u610f\u5473\u7740\u6211\u4eec\u7684\u5411\u91cf\u7684\u5f62\u72b6\u662f <code>[2]</code>\u3002\u8fd9\u662f\u56e0\u4e3a\u6211\u4eec\u5c06\u4e24\u4e2a\u5143\u7d20\u653e\u5728\u4e86\u65b9\u62ec\u53f7\u4e2d\uff08<code>[7, 7]</code>\uff09\u3002</p> <p>\u73b0\u5728\u8ba9\u6211\u4eec\u770b\u4e00\u4e2a\u77e9\u9635\u3002</p> <pre><code># \u77e9\u9635\nMATRIX = torch.tensor([[7, 8], \n                       [9, 10]])\nMATRIX\n</code></pre> <pre><code>tensor([[ 7,  8],\n        [ 9, 10]])\n</code></pre> <p>\u54c7\u54e6\uff01\u66f4\u591a\u7684\u6570\u5b57\uff01\u77e9\u9635\u4e0e\u5411\u91cf\u4e00\u6837\u7075\u6d3b\uff0c\u53ea\u662f\u5b83\u4eec\u6709\u4e00\u4e2a\u989d\u5916\u7684\u7ef4\u5ea6\u3002</p> <pre><code># \u68c0\u67e5\u7ef4\u5ea6\u6570\nMATRIX.ndim\n</code></pre> <pre><code>2\n</code></pre> <p><code>MATRIX</code> \u6709\u4e24\u4e2a\u7ef4\u5ea6\uff08\u4f60\u6709\u6ca1\u6709\u6570\u4e00\u6570\u4e00\u4fa7\u5916\u9762\u7684\u65b9\u62ec\u53f7\uff1f\uff09\u3002</p> <p>\u4f60\u8ba4\u4e3a\u5b83\u4f1a\u6709\u4ec0\u4e48 <code>shape</code>\uff1f</p> <pre><code>MATRIX.shape\n</code></pre> <pre><code>torch.Size([2, 2])\n</code></pre> <p>\u6211\u4eec\u5f97\u5230\u7684\u8f93\u51fa\u662f <code>torch.Size([2, 2])</code>\uff0c\u56e0\u4e3a <code>MATRIX</code> \u6709\u4e24\u4e2a\u5143\u7d20\u6df1\u5ea6\u548c\u4e24\u4e2a\u5143\u7d20\u5bbd\u5ea6\u3002</p> <p>\u90a3\u6211\u4eec\u6765\u521b\u5efa\u4e00\u4e2a\u5f20\u91cf\u5427\uff1f</p> <pre><code># \u5f20\u91cf\nTENSOR = torch.tensor([[[1, 2, 3],\n                        [3, 6, 9],\n                        [2, 4, 5]]])\nTENSOR\n</code></pre> <pre><code>tensor([[[1, 2, 3],\n         [3, 6, 9],\n         [2, 4, 5]]])\n</code></pre> <p>\u54c7\u54e6\uff01\u591a\u597d\u770b\u7684\u5f20\u91cf\u3002</p> <p>\u6211\u60f3\u5f3a\u8c03\u7684\u662f\uff0c\u5f20\u91cf\u53ef\u4ee5\u8868\u793a\u51e0\u4e4e\u4efb\u4f55\u4e1c\u897f\u3002</p> <p>\u6211\u4eec\u521a\u521a\u521b\u5efa\u7684\u8fd9\u4e2a\u53ef\u4ee5\u662f\u725b\u6392\u548c\u674f\u4ec1\u9171\u5e97\u7684\u9500\u552e\u6570\u5b57\uff08\u6211\u6700\u559c\u6b22\u7684\u4e24\u79cd\u98df\u7269\uff09\u3002</p> <p></p> <p>\u5f20\u91cf\u6709\u591a\u5c11\u4e2a\u7ef4\u5ea6\u5462\uff1f\uff08\u63d0\u793a\uff1a\u4f7f\u7528\u65b9\u62ec\u53f7\u8ba1\u6570\u6280\u5de7\uff09</p> <pre><code># \u68c0\u67e5 TENSOR \u7684\u7ef4\u5ea6\u6570\nTENSOR.ndim\n</code></pre> <pre><code>3\n</code></pre> <p>\u5b83\u7684\u5f62\u72b6\u662f\u591a\u5c11\uff1f</p> <pre><code># \u68c0\u67e5 TENSOR \u7684\u5f62\u72b6\nTENSOR.shape\n</code></pre> <pre><code>torch.Size([1, 3, 3])\n</code></pre> <p>\u597d\u7684\uff0c\u5b83\u8f93\u51fa\u4e86 <code>torch.Size([1, 3, 3])</code>\u3002</p> <p>\u7ef4\u5ea6\u662f\u4ece\u5916\u5230\u5185\u6392\u5217\u7684\u3002</p> <p>\u8fd9\u610f\u5473\u7740\u6709 1 \u4e2a 3x3 \u7684\u7ef4\u5ea6\u3002</p> <p></p> <p>\u6ce8\u610f\uff1a \u4f60\u53ef\u80fd\u4f1a\u6ce8\u610f\u5230\u6211\u5728 <code>scalar</code> \u548c <code>vector</code> \u4e2d\u4f7f\u7528\u5c0f\u5199\u5b57\u6bcd\uff0c\u5728 <code>MATRIX</code> \u548c <code>TENSOR</code> \u4e2d\u4f7f\u7528\u5927\u5199\u5b57\u6bcd\u3002\u8fd9\u662f\u6709\u610f\u7684\u3002\u5728\u5b9e\u8df5\u4e2d\uff0c\u6807\u91cf\u548c\u5411\u91cf\u901a\u5e38\u7528\u5c0f\u5199\u5b57\u6bcd\u8868\u793a\uff0c\u4f8b\u5982 <code>y</code> \u6216 <code>a</code>\u3002\u800c\u77e9\u9635\u548c\u5f20\u91cf\u901a\u5e38\u7528\u5927\u5199\u5b57\u6bcd\u8868\u793a\uff0c\u4f8b\u5982 <code>X</code> \u6216 <code>W</code>\u3002</p> <p>\u4f60\u8fd8\u53ef\u80fd\u6ce8\u610f\u5230\u77e9\u9635\u548c\u5f20\u91cf\u7684\u540d\u79f0\u53ef\u4ee5\u4e92\u6362\u4f7f\u7528\u3002\u8fd9\u662f\u5e38\u89c1\u7684\u3002\u7531\u4e8e\u5728 PyTorch \u4e2d\u901a\u5e38\u5904\u7406 <code>torch.Tensor</code>\uff08\u56e0\u6b64\u6709\u5f20\u91cf\u540d\u79f0\uff09\uff0c\u4f46\u5176\u4e2d\u7684\u5185\u5bb9\u7684\u5f62\u72b6\u548c\u7ef4\u5ea6\u5c06\u51b3\u5b9a\u5b83\u5b9e\u9645\u4e0a\u662f\u4ec0\u4e48\u3002</p> <p>\u8ba9\u6211\u4eec\u603b\u7ed3\u4e00\u4e0b\u3002</p> \u540d\u79f0 \u5b83\u662f\u4ec0\u4e48\uff1f \u7ef4\u5ea6\u6570 \u5927\u5199\u6216\u5c0f\u5199\uff08\u901a\u5e38/\u793a\u4f8b\uff09 \u6807\u91cf \u4e00\u4e2a\u5355\u72ec\u7684\u6570\u5b57 0 \u5c0f\u5199\uff08<code>a</code>\uff09 \u5411\u91cf \u6709\u65b9\u5411\u7684\u6570\u5b57\uff08\u4f8b\u5982\u5e26\u6709\u65b9\u5411\u7684\u98ce\u901f\uff09\uff0c\u4f46\u4e5f\u53ef\u4ee5\u5305\u542b\u8bb8\u591a\u5176\u4ed6\u6570\u5b57 1 \u5c0f\u5199\uff08<code>y</code>\uff09 \u77e9\u9635 \u6570\u5b57\u7684 2 \u7ef4\u6570\u7ec4 2 \u5927\u5199\uff08<code>Q</code>\uff09 \u5f20\u91cf \u6570\u5b57\u7684 n \u7ef4\u6570\u7ec4 \u53ef\u4ee5\u662f\u4efb\u4f55\u6570\u5b57\uff0c0 \u7ef4\u5f20\u91cf\u662f\u6807\u91cf\uff0c1 \u7ef4\u5f20\u91cf\u662f\u5411\u91cf \u5927\u5199\uff08<code>X</code>\uff09 <p></p>"},{"location":"tutorials/00_pytorch_fundamentals/#_4","title":"\u968f\u673a\u5f20\u91cf","text":"<p>\u6211\u4eec\u5df2\u7ecf\u786e\u5b9a\u5f20\u91cf\u8868\u793a\u67d0\u79cd\u5f62\u5f0f\u7684\u6570\u636e\u3002</p> <p>\u800c\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u5982\u795e\u7ecf\u7f51\u7edc\uff0c\u5219\u64cd\u4f5c\u5e76\u5bfb\u627e\u5f20\u91cf\u4e2d\u7684\u6a21\u5f0f\u3002</p> <p>\u4f46\u662f\u5728\u4f7f\u7528 PyTorch \u6784\u5efa\u673a\u5668\u5b66\u4e60\u6a21\u578b\u65f6\uff0c\u4f60\u5f88\u5c11\u4f1a\u624b\u52a8\u521b\u5efa\u5f20\u91cf\uff08\u5c31\u50cf\u6211\u4eec\u4e00\u76f4\u5728\u505a\u7684\u90a3\u6837\uff09\u3002</p> <p>\u76f8\u53cd\uff0c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u901a\u5e38\u4ee5\u5927\u578b\u968f\u673a\u6570\u5f20\u91cf\u5f00\u59cb\uff0c\u5e76\u5728\u5904\u7406\u6570\u636e\u4ee5\u66f4\u597d\u5730\u8868\u793a\u6570\u636e\u65f6\u8c03\u6574\u8fd9\u4e9b\u968f\u673a\u6570\u3002</p> <p>\u5b9e\u8d28\u4e0a\uff1a</p> <p><code>\u4ece\u968f\u673a\u6570\u5f00\u59cb -&gt; \u67e5\u770b\u6570\u636e -&gt; \u66f4\u65b0\u968f\u673a\u6570 -&gt; \u67e5\u770b\u6570\u636e -&gt; \u66f4\u65b0\u968f\u673a\u6570...</code></p> <p>\u4f5c\u4e3a\u6570\u636e\u79d1\u5b66\u5bb6\uff0c\u4f60\u53ef\u4ee5\u5b9a\u4e49\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5f00\u59cb\uff08\u521d\u59cb\u5316\uff09\u3001\u67e5\u770b\u6570\u636e\uff08\u8868\u793a\uff09\u548c\u66f4\u65b0\uff08\u4f18\u5316\uff09\u5176\u968f\u673a\u6570\u7684\u65b9\u5f0f\u3002</p> <p>\u7a0d\u540e\u6211\u4eec\u5c06\u4eb2\u81ea\u52a8\u624b\u64cd\u4f5c\u8fd9\u4e9b\u6b65\u9aa4\u3002</p> <p>\u73b0\u5728\uff0c\u8ba9\u6211\u4eec\u770b\u770b\u5982\u4f55\u521b\u5efa\u4e00\u4e2a\u968f\u673a\u6570\u5f20\u91cf\u3002</p> <p>\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 <code>torch.rand()</code> \u5e76\u4f20\u9012 <code>size</code> \u53c2\u6570\u6765\u5b9e\u73b0\u8fd9\u4e00\u70b9\u3002</p> <pre><code># \u521b\u5efa\u4e00\u4e2a\u5927\u5c0f\u4e3a (3, 4) \u7684\u968f\u673a\u6570\u5f20\u91cf\nrandom_tensor = torch.rand(size=(3, 4))\nrandom_tensor, random_tensor.dtype\n</code></pre> <pre><code>(tensor([[0.6541, 0.4807, 0.2162, 0.6168],\n         [0.4428, 0.6608, 0.6194, 0.8620],\n         [0.2795, 0.6055, 0.4958, 0.5483]]),\n torch.float32)\n</code></pre> <p><code>torch.rand()</code> \u7684\u7075\u6d3b\u6027\u5728\u4e8e\u6211\u4eec\u53ef\u4ee5\u8c03\u6574 <code>size</code> \u4e3a\u4efb\u4f55\u6211\u4eec\u60f3\u8981\u7684\u5927\u5c0f\u3002</p> <p>\u4f8b\u5982\uff0c\u5047\u8bbe\u4f60\u60f3\u8981\u4e00\u4e2a\u968f\u673a\u6570\u5f20\u91cf\uff0c\u5176\u5f62\u72b6\u4e3a\u5e38\u89c1\u7684\u56fe\u50cf\u5f62\u72b6 <code>[224, 224, 3]</code>\uff08<code>[\u9ad8\u5ea6\uff0c\u5bbd\u5ea6\uff0c\u989c\u8272\u901a\u9053]</code>\uff09\u3002</p> <pre><code># \u521b\u5efa\u4e00\u4e2a\u5927\u5c0f\u4e3a (224, 224, 3) \u7684\u968f\u673a\u6570\u5f20\u91cf\nrandom_image_size_tensor = torch.rand(size=(224, 224, 3))\nrandom_image_size_tensor.shape, random_image_size_tensor.ndim\n</code></pre> <pre><code>(torch.Size([224, 224, 3]), 3)\n</code></pre>"},{"location":"tutorials/00_pytorch_fundamentals/#zerosones","title":"\u96f6zeros\u548c\u4e00ones","text":"<p>\u6709\u65f6\u4f60\u53ea\u60f3\u7528\u96f6\u6216\u4e00\u6765\u586b\u5145\u5f20\u91cf\u3002</p> <p>\u8fd9\u5728\u63a9\u7801\uff08\u4f8b\u5982\uff0c\u7528\u96f6\u63a9\u76d6\u4e00\u4e2a\u5f20\u91cf\u4e2d\u7684\u67d0\u4e9b\u503c\uff0c\u4ee5\u901a\u77e5\u6a21\u578b\u4e0d\u8981\u5b66\u4e60\u5b83\u4eec\uff09\u4e2d\u7ecf\u5e38\u53d1\u751f\u3002</p> <p>\u8ba9\u6211\u4eec\u521b\u5efa\u4e00\u4e2a\u5168\u96f6\u7684\u5f20\u91cf\uff0c\u4f7f\u7528 <code>torch.zeros()</code>\u3002</p> <p>\u540c\u6837\uff0c<code>size</code> \u53c2\u6570\u53d1\u6325\u4f5c\u7528\u3002</p> <pre><code># \u521b\u5efa\u4e00\u4e2a\u5168\u96f6\u7684\u5f20\u91cf\nzeros = torch.zeros(size=(3, 4))\nzeros, zeros.dtype\n</code></pre> <pre><code>(tensor([[0., 0., 0., 0.],\n         [0., 0., 0., 0.],\n         [0., 0., 0., 0.]]),\n torch.float32)\n</code></pre> <p>\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 <code>torch.ones()</code>  \u6765\u521b\u5efa\u4e00\u4e2a\u5168\u4e3a\u4e00\u7684\u5f20\u91cf\u3002</p> <pre><code># \u521b\u5efa\u4e00\u4e2a\u5168\u4e3a\u4e00\u7684\u5f20\u91cf\nones = torch.ones(size=(3, 4))\nones, ones.dtype\n</code></pre> <pre><code>(tensor([[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]]),\n torch.float32)\n</code></pre>"},{"location":"tutorials/00_pytorch_fundamentals/#rangetensors-like","title":"\u521b\u5efa\u8303\u56f4range\u548c\u7c7b\u4f3c\u7684\u5f20\u91cftensors like","text":"<p>\u6709\u65f6\u4f60\u53ef\u80fd\u60f3\u8981\u4e00\u7cfb\u5217\u6570\u5b57\uff0c\u4f8b\u5982 1 \u5230 10 \u6216 0 \u5230 100\u3002</p> <p>\u4f60\u53ef\u4ee5\u4f7f\u7528 <code>torch.arange(start, end, step)</code> \u6765\u5b9e\u73b0\u3002</p> <p>\u5176\u4e2d\uff1a</p> <ul> <li><code>start</code> = \u8303\u56f4\u7684\u8d77\u59cb\u4f4d\u7f6e\uff08\u4f8b\u5982 0\uff09</li> <li><code>end</code> = \u8303\u56f4\u7684\u7ed3\u675f\u4f4d\u7f6e\uff08\u4f8b\u5982 10\uff09</li> <li><code>step</code> = \u6bcf\u4e2a\u503c\u4e4b\u95f4\u7684\u6b65\u957f\uff08\u4f8b\u5982 1\uff09</li> </ul> <p>\u6ce8\u610f\uff1a \u5728 Python \u4e2d\uff0c\u4f60\u53ef\u4ee5\u4f7f\u7528 <code>range()</code> \u6765\u521b\u5efa\u8303\u56f4\u3002\u4f46\u662f\u5728 PyTorch \u4e2d\uff0c<code>torch.range()</code> \u5df2\u88ab\u5f03\u7528\uff0c\u5e76\u4e14\u5728\u672a\u6765\u53ef\u80fd\u4f1a\u51fa\u73b0\u9519\u8bef\u3002</p> <pre><code># \u4f7f\u7528 torch.arange()\uff0ctorch.range() \u5df2\u88ab\u5f03\u7528\nzero_to_ten_deprecated = torch.range(0, 10) # \u6ce8\u610f\uff1a\u672a\u6765\u53ef\u80fd\u4f1a\u51fa\u73b0\u9519\u8bef\n\n# \u521b\u5efa\u503c\u4ece 0 \u5230 10 \u7684\u4e00\u7cfb\u5217\u503c\nzero_to_ten = torch.arange(start=0, end=10, step=1)\nzero_to_ten\n</code></pre> <pre><code>/tmp/ipykernel_3695928/193451495.py:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n  zero_to_ten_deprecated = torch.range(0, 10) # Note: this may return an error in the future\n</code></pre> <pre><code>tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n</code></pre> <p>\u6709\u65f6\u4f60\u53ef\u80fd\u60f3\u8981\u4e00\u4e2a\u4e0e\u53e6\u4e00\u4e2a\u5f20\u91cf\u5177\u6709\u76f8\u540c\u5f62\u72b6\u7684\u76f8\u540c\u7c7b\u578b\u7684\u5f20\u91cf\u3002</p> <p>\u4f8b\u5982\uff0c\u4e00\u4e2a\u5f20\u91cf\u7684\u5f62\u72b6\u4e3a 0 \u7684\u5168\u90e8\u96f6\u5f20\u91cf\u3002</p> <p>\u4f60\u53ef\u4ee5\u4f7f\u7528 <code>torch.zeros_like(input)</code> \u6216 <code>torch.ones_like(input)</code> \u6765\u5b9e\u73b0\uff0c\u5b83\u4eec\u5206\u522b\u8fd4\u56de\u4e00\u4e2a\u4ee5 <code>input</code> \u7684\u5f62\u72b6\u586b\u5145\u4e86\u96f6\u6216\u4e00\u7684\u5f20\u91cf\u3002</p> <pre><code># \u4e5f\u53ef\u4ee5\u521b\u5efa\u4e00\u4e2a\u4e0e\u53e6\u4e00\u4e2a\u5f20\u91cf\u5177\u6709\u76f8\u540c\u5f62\u72b6\u7684\u5168\u90e8\u96f6\u5f20\u91cf\nten_zeros = torch.zeros_like(input=zero_to_ten) # \u5f62\u72b6\u76f8\u540c\nten_zeros\n</code></pre> <pre><code>tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n</code></pre>"},{"location":"tutorials/00_pytorch_fundamentals/#_5","title":"\u5f20\u91cf\u6570\u636e\u7c7b\u578b","text":"<p>PyTorch \u4e2d\u6709\u8bb8\u591a\u4e0d\u540c\u7684\u5f20\u91cf\u6570\u636e\u7c7b\u578b\u53ef\u7528\u3002</p> <p>\u6709\u4e9b\u662f\u7279\u5b9a\u4e8e CPU \u7684\uff0c\u6709\u4e9b\u5bf9 GPU \u66f4\u597d\u3002</p> <p>\u4e86\u89e3\u54ea\u79cd\u662f\u54ea\u79cd\u53ef\u80fd\u9700\u8981\u4e00\u4e9b\u65f6\u95f4\u3002</p> <p>\u901a\u5e38\uff0c\u5982\u679c\u5728\u4efb\u4f55\u5730\u65b9\u770b\u5230 <code>torch.cuda</code>\uff0c\u5219\u8868\u793a\u5f20\u91cf\u6b63\u5728\u7528\u4e8e GPU\uff08\u56e0\u4e3a Nvidia GPU \u4f7f\u7528\u540d\u4e3a CUDA \u7684\u8ba1\u7b97\u5de5\u5177\u5305\uff09\u3002</p> <p>\u6700\u5e38\u89c1\u7684\u7c7b\u578b\uff08\u901a\u5e38\u662f\u9ed8\u8ba4\u7684\uff09\u662f <code>torch.float32</code> \u6216 <code>torch.float</code>\u3002</p> <p>\u8fd9\u88ab\u79f0\u4e3a \"32 \u4f4d\u6d6e\u70b9\"\u3002</p> <p>\u4f46\u8fd8\u6709 16 \u4f4d\u6d6e\u70b9\u6570\uff08<code>torch.float16</code> \u6216 <code>torch.half</code>\uff09\u548c 64 \u4f4d\u6d6e\u70b9\u6570\uff08<code>torch.float64</code> \u6216 <code>torch.double</code>\uff09\u3002</p> <p>\u4e3a\u4e86\u4f7f\u4e8b\u60c5\u53d8\u5f97\u66f4\u52a0\u6df7\u4e71\uff0c\u8fd8\u6709 8 \u4f4d\u300116 \u4f4d\u300132 \u4f4d\u548c 64 \u4f4d\u6574\u6570\u3002</p> <p>\u8fd8\u6709\u66f4\u591a\uff01</p> <p>\u6ce8\u610f\uff1a \u6574\u6570integer\u662f\u4e00\u4e2a\u6570\u5b57\uff0c\u4f8b\u5982 <code>7</code>\uff0c\u800c\u6d6e\u70b9\u6570\u5e26\u6709\u5c0f\u6570 <code>7.0</code>\u3002</p> <p>\u8fd9\u4e00\u5207\u7684\u539f\u56e0\u90fd\u4e0e\u8ba1\u7b97\u4e2d\u7684\u7cbe\u5ea6\u6709\u5173\u3002</p> <p>\u7cbe\u5ea6\u662f\u7528\u4e8e\u63cf\u8ff0\u6570\u5b57\u7684\u8be6\u7ec6\u7a0b\u5ea6\u3002</p> <p>\u7cbe\u5ea6\u503c\u8d8a\u9ad8\uff088\u300116\u300132\uff09\uff0c\u63cf\u8ff0\u6570\u5b57\u7684\u7ec6\u8282\u548c\u6570\u636e\u8d8a\u591a\u3002</p> <p>\u5728\u6df1\u5ea6\u5b66\u4e60\u548c\u6570\u503c\u8ba1\u7b97\u4e2d\uff0c\u8fd9\u5f88\u91cd\u8981\uff0c\u56e0\u4e3a\u4f60\u6b63\u5728\u6267\u884c\u5982\u6b64\u591a\u7684\u64cd\u4f5c\uff0c\u4f60\u62e5\u6709\u7684\u7ec6\u8282\u8d8a\u591a\uff0c\u8fdb\u884c\u8ba1\u7b97\u6240\u9700\u7684\u8ba1\u7b97\u91cf\u5c31\u8d8a\u5927\u3002</p> <p>\u56e0\u6b64\uff0c\u4f4e\u7cbe\u5ea6\u6570\u636e\u7c7b\u578b\u901a\u5e38\u8ba1\u7b97\u901f\u5ea6\u66f4\u5feb\uff0c\u4f46\u5728\u8bc4\u4f30\u6307\u6807\uff08\u8ba1\u7b97\u901f\u5ea6\u66f4\u5feb\u4f46\u51c6\u786e\u6027\u8f83\u4f4e\uff09\u65b9\u9762\u4f1a\u727a\u7272\u4e00\u4e9b\u6027\u80fd\u3002</p> <p>\u8d44\u6e90\uff1a</p> <ul> <li>\u8bf7\u53c2\u9605PyTorch\u6587\u6863\u4ee5\u83b7\u53d6\u6240\u6709\u53ef\u7528\u5f20\u91cf\u6570\u636e\u7c7b\u578b\u7684\u5217\u8868\u3002</li> <li>\u9605\u8bfb\u7ef4\u57fa\u767e\u79d1\u9875\u9762\uff0c\u4e86\u89e3\u8ba1\u7b97\u4e2d\u7684\u7cbe\u5ea6\u662f\u4ec0\u4e48\u3002</li> </ul> <p>\u8ba9\u6211\u4eec\u770b\u770b\u5982\u4f55\u4f7f\u7528\u7279\u5b9a\u6570\u636e\u7c7b\u578b\u521b\u5efa\u4e00\u4e9b\u5f20\u91cf\u3002\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 <code>dtype</code> \u53c2\u6570\u6765\u5b9e\u73b0\u3002</p> <pre><code># \u5f20\u91cf\u7684\u9ed8\u8ba4\u6570\u636e\u7c7b\u578b\u662f float32\nfloat_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n                               dtype=None, # \u9ed8\u8ba4\u4e3a None\uff0c\u5373 torch.float32 \u6216\u4f20\u9012\u7684\u4efb\u4f55\u6570\u636e\u7c7b\u578b\n                               device=None, # \u9ed8\u8ba4\u4e3a None\uff0c\u4f7f\u7528\u9ed8\u8ba4\u5f20\u91cf\u7c7b\u578b\n                               requires_grad=False) # \u5982\u679c\u4e3a True\uff0c\u5219\u8bb0\u5f55\u5728\u5f20\u91cf\u4e0a\u6267\u884c\u7684\u64cd\u4f5c\n\nfloat_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device\n</code></pre> <pre><code>(torch.Size([3]), torch.float32, device(type='cpu'))\n</code></pre> <p>\u9664\u4e86\u5f62\u72b6\u95ee\u9898\uff08\u5f20\u91cf\u5f62\u72b6\u4e0d\u5339\u914d\uff09\uff0c\u4f60\u5c06\u5728 PyTorch \u4e2d\u9047\u5230\u7684\u53e6\u5916\u4e24\u4e2a\u6700\u5e38\u89c1\u7684\u95ee\u9898\u662f\u6570\u636e\u7c7b\u578b\u548c\u8bbe\u5907\u95ee\u9898\u3002</p> <p>\u4f8b\u5982\uff0c\u5176\u4e2d\u4e00\u4e2a\u5f20\u91cf\u662f <code>torch.float32</code>\uff0c\u53e6\u4e00\u4e2a\u662f <code>torch.float16</code>\uff08PyTorch \u901a\u5e38\u5e0c\u671b\u5f20\u91cf\u5177\u6709\u76f8\u540c\u7684\u683c\u5f0f\uff09\u3002</p> <p>\u6216\u8005\u4e00\u4e2a\u5f20\u91cf\u4f4d\u4e8e CPU \u4e0a\uff0c\u53e6\u4e00\u4e2a\u4f4d\u4e8e GPU \u4e0a\uff08PyTorch \u5e0c\u671b\u5728\u76f8\u540c\u8bbe\u5907\u4e0a\u8fdb\u884c\u5f20\u91cf\u4e4b\u95f4\u7684\u8ba1\u7b97\uff09\u3002</p> <p>\u7a0d\u540e\u6211\u4eec\u5c06\u770b\u5230\u66f4\u591a\u5173\u4e8e\u8bbe\u5907\u7684\u8ba8\u8bba\u3002</p> <p>\u73b0\u5728\uff0c\u8ba9\u6211\u4eec\u521b\u5efa\u4e00\u4e2a <code>dtype=torch.float16</code> \u7684\u5f20\u91cf\u3002</p> <pre><code>float_16_tensor = torch.tensor([3.0, 6.0, 9.0],\n                               dtype=torch.float16) # torch.half \u4e5f\u53ef\u4ee5\u5de5\u4f5c\n\nfloat_16_tensor.dtype\n</code></pre> <pre><code>torch.float16\n</code></pre>"},{"location":"tutorials/00_pytorch_fundamentals/#_6","title":"\u4ece\u5f20\u91cf\u83b7\u53d6\u4fe1\u606f","text":"<p>\u4e00\u65e6\u4f60\u521b\u5efa\u4e86\u5f20\u91cf\uff08\u6216\u5176\u4ed6\u4eba\u6216 PyTorch \u6a21\u5757\u4e3a\u4f60\u521b\u5efa\u4e86\u5b83\u4eec\uff09\uff0c\u4f60\u53ef\u80fd\u5e0c\u671b\u4ece\u4e2d\u83b7\u53d6\u4e00\u4e9b\u4fe1\u606f\u3002</p> <p>\u6211\u4eec\u4e4b\u524d\u5df2\u7ecf\u770b\u5230\u4e86\u8fd9\u4e9b\u4fe1\u606f\uff0c\u4f46\u4f60\u53ef\u80fd\u60f3\u8981\u4e86\u89e3\u5f20\u91cf\u7684\u4e09\u4e2a\u6700\u5e38\u89c1\u5c5e\u6027\uff1a</p> <ul> <li><code>shape</code> - \u5f20\u91cf\u7684\u5f62\u72b6\u662f\u4ec0\u4e48\uff1f\uff08\u4e00\u4e9b\u64cd\u4f5c\u9700\u8981\u7279\u5b9a\u7684\u5f62\u72b6\u89c4\u5219\uff09</li> <li><code>dtype</code> - \u5f20\u91cf\u4e2d\u7684\u5143\u7d20\u5b58\u50a8\u5728\u4ec0\u4e48\u6570\u636e\u7c7b\u578b\u4e2d\uff1f</li> <li><code>device</code> - \u5f20\u91cf\u5b58\u50a8\u5728\u4ec0\u4e48\u8bbe\u5907\u4e0a\uff1f\uff08\u901a\u5e38\u662f GPU \u6216 CPU\uff09</li> </ul> <p>\u8ba9\u6211\u4eec\u521b\u5efa\u4e00\u4e2a\u968f\u673a\u5f20\u91cf\u5e76\u67e5\u627e\u6709\u5173\u5b83\u7684\u8be6\u7ec6\u4fe1\u606f\u3002</p> <pre><code># \u521b\u5efa\u4e00\u4e2a\u5f20\u91cf\nsome_tensor = torch.rand(3, 4)\n\n# \u67e5\u627e\u6709\u5173\u5b83\u7684\u8be6\u7ec6\u4fe1\u606f\nprint(some_tensor)\nprint(f\"\u5f20\u91cf\u7684\u5f62\u72b6\uff1a{some_tensor.shape}\")\nprint(f\"\u5f20\u91cf\u7684\u6570\u636e\u7c7b\u578b\uff1a{some_tensor.dtype}\")\nprint(f\"\u5f20\u91cf\u5b58\u50a8\u5728\u7684\u8bbe\u5907\uff1a{some_tensor.device}\") # \u9ed8\u8ba4\u4e3a CPU\n</code></pre> <pre><code>tensor([[0.4688, 0.0055, 0.8551, 0.0646],\n        [0.6538, 0.5157, 0.4071, 0.2109],\n        [0.9960, 0.3061, 0.9369, 0.7008]])\n\u5f20\u91cf\u7684\u5f62\u72b6\uff1atorch.Size([3, 4])\n\u5f20\u91cf\u7684\u6570\u636e\u7c7b\u578b\uff1atorch.float32\n\u5f20\u91cf\u5b58\u50a8\u5728\u7684\u8bbe\u5907\uff1acpu\n</code></pre> <p>\u6ce8\u610f\uff1a \u5f53\u5728 PyTorch \u4e2d\u9047\u5230\u95ee\u9898\u65f6\uff0c\u5f88\u5e38\u89c1\u7684\u95ee\u9898\u4e4b\u4e00\u5f80\u5f80\u4e0e\u4e0a\u9762\u63d0\u5230\u7684\u4e09\u4e2a\u5c5e\u6027\u4e4b\u4e00\u6709\u5173\u3002</p>"},{"location":"tutorials/00_pytorch_fundamentals/#_7","title":"\u64cd\u4f5c\u5f20\u91cf\uff08\u5f20\u91cf\u8fd0\u7b97\uff09","text":"<p>\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\uff0c\u6570\u636e\uff08\u56fe\u50cf\u3001\u6587\u672c\u3001\u89c6\u9891\u3001\u97f3\u9891\u3001\u86cb\u767d\u8d28\u7ed3\u6784\u7b49\uff09\u88ab\u8868\u793a\u4e3a\u5f20\u91cf\u3002</p> <p>\u6a21\u578b\u901a\u8fc7\u7814\u7a76\u8fd9\u4e9b\u5f20\u91cf\u5e76\u5bf9\u5f20\u91cf\u6267\u884c\u4e00\u7cfb\u5217\u64cd\u4f5c\uff08\u53ef\u80fd\u662f 1,000,000s+\uff09\u6765\u521b\u5efa\u8f93\u5165\u6570\u636e\u4e2d\u6a21\u5f0f\u7684\u8868\u793a\u3002</p> <p>\u8fd9\u4e9b\u64cd\u4f5c\u901a\u5e38\u662f\u4ee5\u4e0b\u51e0\u79cd\u57fa\u672c\u64cd\u4f5c\u4e4b\u95f4\u7684\u7cbe\u5999\u534f\u8c03\uff1a</p> <ul> <li>\u52a0\u6cd5</li> <li>\u51cf\u6cd5</li> <li>\u4e58\u6cd5\uff08\u9010\u5143\u7d20\uff09</li> <li>\u9664\u6cd5</li> <li>\u77e9\u9635\u4e58\u6cd5</li> </ul> <p>\u8fd9\u5c31\u662f\u5168\u90e8\u3002\u5f53\u7136\uff0c\u8fd8\u6709\u4e00\u4e9b\u5176\u4ed6\u64cd\u4f5c\uff0c\u4f46\u8fd9\u4e9b\u662f\u795e\u7ecf\u7f51\u7edc\u7684\u57fa\u672c\u6784\u5efa\u5757\u3002</p> <p>\u5c06\u8fd9\u4e9b\u6784\u5efa\u5757\u4ee5\u6b63\u786e\u7684\u65b9\u5f0f\u5806\u53e0\u8d77\u6765\uff0c\u4f60\u53ef\u4ee5\u521b\u5efa\u6700\u590d\u6742\u7684\u795e\u7ecf\u7f51\u7edc\uff08\u5c31\u50cf\u79ef\u6728\u4e00\u6837\uff01\uff09\u3002</p>"},{"location":"tutorials/00_pytorch_fundamentals/#_8","title":"\u57fa\u672c\u64cd\u4f5c","text":"<p>\u8ba9\u6211\u4eec\u4ece\u4e00\u4e9b\u57fa\u672c\u64cd\u4f5c\u5f00\u59cb\uff0c\u52a0\u6cd5\uff08<code>+</code>\uff09\u3001\u51cf\u6cd5\uff08<code>-</code>\uff09\u548c\u4e58\u6cd5\uff08<code>*</code>\uff09\u3002</p> <p>\u5b83\u4eec\u7684\u5de5\u4f5c\u65b9\u5f0f\u5c31\u50cf\u4f60\u60f3\u8c61\u7684\u90a3\u6837\u3002</p> <pre><code># \u521b\u5efa\u4e00\u4e2a\u6570\u503c\u5f20\u91cf\u5e76\u5c06\u4e00\u4e2a\u6570\u5b57\u52a0\u5230\u5b83\u4e0a\u9762\ntensor = torch.tensor([1, 2, 3])\ntensor + 10\n</code></pre> <pre><code>tensor([11, 12, 13])\n</code></pre> <pre><code># \u5c06\u5176\u4e58\u4ee5 10\ntensor * 10\n</code></pre> <pre><code>tensor([10, 20, 30])\n</code></pre> <p>\u8bf7\u6ce8\u610f\uff0c\u4e0a\u9762\u7684\u5f20\u91cf\u503c\u6700\u7ec8\u4e0d\u4f1a\u53d8\u6210 <code>tensor([110, 120, 130])</code>\uff0c\u8fd9\u662f\u56e0\u4e3a\u5f20\u91cf\u5185\u90e8\u7684\u503c\u4e0d\u4f1a\u66f4\u6539\uff0c\u9664\u975e\u91cd\u65b0\u5206\u914d\u3002</p> <pre><code># \u9664\u975e\u91cd\u65b0\u5206\u914d\uff0c\u5426\u5219\u5f20\u91cf\u4e0d\u4f1a\u6539\u53d8\ntensor\n</code></pre> <pre><code>tensor([1, 2, 3])\n</code></pre> <p>\u8ba9\u6211\u4eec\u51cf\u53bb\u4e00\u4e2a\u6570\u5b57\uff0c\u8fd9\u6b21\u6211\u4eec\u5c06\u91cd\u65b0\u5206\u914d <code>tensor</code> \u53d8\u91cf\u3002</p> <pre><code># \u51cf\u53bb\u5e76\u91cd\u65b0\u5206\u914d\ntensor = tensor - 10\ntensor\n</code></pre> <pre><code>tensor([-9, -8, -7])\n</code></pre> <pre><code># \u52a0\u4e0a\u5e76\u91cd\u65b0\u5206\u914d\ntensor = tensor + 10\ntensor\n</code></pre> <pre><code>tensor([1, 2, 3])\n</code></pre> <p>PyTorch \u8fd8\u6709\u8bb8\u591a\u5185\u7f6e\u51fd\u6570\uff0c\u5982 <code>torch.mul()</code>\uff08multiplication\u7684\u7f29\u5199\uff09\u548c <code>torch.add()</code> \u6765\u6267\u884c\u57fa\u672c\u64cd\u4f5c\u3002</p> <pre><code># \u4e5f\u53ef\u4ee5\u4f7f\u7528 torch \u51fd\u6570\ntorch.multiply(tensor, 10)\n</code></pre> <pre><code>tensor([10, 20, 30])\n</code></pre> <pre><code># \u539f\u59cb\u5f20\u91cf\u4ecd\u7136\u4e0d\u53d8\ntensor\n</code></pre> <pre><code>tensor([1, 2, 3])\n</code></pre> <p>\u4f46\u901a\u5e38\u4f7f\u7528\u8fd0\u7b97\u7b26\u7b26\u53f7\uff0c\u5982 <code>*</code>\uff0c\u800c\u4e0d\u662f <code>torch.mul()</code>\u3002</p> <pre><code># \u9010\u5143\u7d20\u4e58\u6cd5\uff08\u6bcf\u4e2a\u5143\u7d20\u90fd\u4e0e\u5176\u76f8\u5bf9\u5e94\u7684\u5143\u7d20\u76f8\u4e58\uff0c\u7d22\u5f15 0-&gt;0\uff0c1-&gt;1\uff0c2-&gt;2\uff09\nprint(tensor, \"*\", tensor)\nprint(\"\u76f8\u7b49\u4e8e\uff1a\", tensor * tensor)\n</code></pre> <pre><code>tensor([1, 2, 3]) * tensor([1, 2, 3])\nEquals: tensor([1, 4, 9])\n</code></pre>"},{"location":"tutorials/00_pytorch_fundamentals/#_9","title":"\u77e9\u9635\u4e58\u6cd5\uff08\u4f60\u6240\u9700\u8981\u7684\u4e00\u5207\uff09","text":"<p>\u5728\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u7b97\u6cd5\uff08\u5982\u795e\u7ecf\u7f51\u7edc\uff09\u4e2d\uff0c\u6700\u5e38\u89c1\u7684\u64cd\u4f5c\u4e4b\u4e00\u662f\u77e9\u9635\u4e58\u6cd5\u3002</p> <p>PyTorch \u5728 <code>torch.matmul()</code> \u65b9\u6cd5\u4e2d\u5b9e\u73b0\u4e86\u77e9\u9635\u4e58\u6cd5\u529f\u80fd\u3002</p> <p>\u8bb0\u4f4f\u77e9\u9635\u4e58\u6cd5\u7684\u4e24\u4e2a\u4e3b\u8981\u89c4\u5219\uff1a</p> <ol> <li>\u5185\u90e8\u5c3a\u5bf8 \u5fc5\u987b\u5339\u914d\uff1a</li> <li><code>(3, 2) @ (3, 2)</code> \u4e0d\u8d77\u4f5c\u7528</li> <li><code>(2, 3) @ (3, 2)</code> \u8d77\u4f5c\u7528</li> <li> <p><code>(3, 2) @ (2, 3)</code> \u8d77\u4f5c\u7528</p> </li> <li> <p>\u7ed3\u679c\u77e9\u9635\u5177\u6709 \u5916\u90e8\u5c3a\u5bf8 \u7684\u5f62\u72b6\uff1a</p> </li> <li><code>(2, 3) @ (3, 2)</code> -&gt; <code>(2, 2)</code></li> <li><code>(3, 2) @ (2, 3)</code> -&gt; <code>(3, 3)</code></li> </ol> <p>\u6ce8\u610f\uff1a \u5728 Python \u4e2d\uff0c\u201c<code>@</code>\u201d\u662f\u77e9\u9635\u4e58\u6cd5\u7684\u7b26\u53f7\u3002</p> <p>\u8d44\u6e90\uff1a \u4f60\u53ef\u4ee5\u5728 PyTorch \u6587\u6863\u4e2d\u67e5\u770b <code>torch.matmul()</code> \u7684\u6240\u6709\u77e9\u9635\u4e58\u6cd5\u89c4\u5219 \u94fe\u63a5\u3002</p> <p>\u8ba9\u6211\u4eec\u521b\u5efa\u4e00\u4e2a\u5f20\u91cf\u5e76\u5bf9\u5176\u6267\u884c\u9010\u5143\u7d20\u4e58\u6cd5\u548c\u77e9\u9635\u4e58\u6cd5\u3002</p> <pre><code>import torch\ntensor = torch.tensor([1, 2, 3])\ntensor.shape\n</code></pre> <pre><code>torch.Size([3])\n</code></pre> <p>\u9010\u5143\u7d20\u4e58\u6cd5\u548c\u77e9\u9635\u4e58\u6cd5\u4e4b\u95f4\u7684\u533a\u522b\u5728\u4e8e\u503c\u7684\u6dfb\u52a0\u3002</p> <p>\u5bf9\u4e8e\u5177\u6709\u503c <code>[1, 2, 3]</code> \u7684 <code>tensor</code> \u53d8\u91cf\uff1a</p> \u64cd\u4f5c \u8ba1\u7b97 \u4ee3\u7801 \u9010\u5143\u7d20\u4e58\u6cd5 <code>[1*1, 2*2, 3*3]</code> = <code>[1, 4, 9]</code> <code>tensor * tensor</code> \u77e9\u9635\u4e58\u6cd5 <code>[1*1 + 2*2 + 3*3]</code> = <code>[14]</code> <code>tensor.matmul(tensor)</code> <pre><code># \u9010\u5143\u7d20\u77e9\u9635\u4e58\u6cd5\ntensor * tensor\n</code></pre> <pre><code>tensor([1, 4, 9])\n</code></pre> <pre><code># \u77e9\u9635\u4e58\u6cd5\ntorch.matmul(tensor, tensor)\n</code></pre> <pre><code>tensor(14)\n</code></pre> <pre><code># \u4e5f\u53ef\u4ee5\u4f7f\u7528 \"@\" \u7b26\u53f7\u8fdb\u884c\u77e9\u9635\u4e58\u6cd5\uff0c\u4e0d\u8fc7\u4e0d\u63a8\u8350\ntensor @ tensor\n</code></pre> <pre><code>tensor(14)\n</code></pre> <p>\u4f60\u53ef\u4ee5\u624b\u52a8\u6267\u884c\u77e9\u9635\u4e58\u6cd5\uff0c\u4f46\u4e0d\u63a8\u8350\u8fd9\u6837\u505a\u3002</p> <p>\u5185\u7f6e\u7684 <code>torch.matmul()</code> \u65b9\u6cd5\u901f\u5ea6\u66f4\u5feb\u3002</p> <pre><code>%%time\n# \u624b\u52a8\u6267\u884c\u77e9\u9635\u4e58\u6cd5\n# \uff08\u5c3d\u91cf\u907f\u514d\u4f7f\u7528 for \u5faa\u73af\u8fdb\u884c\u64cd\u4f5c\uff0c\u5b83\u4eec\u5728\u8ba1\u7b97\u4e0a\u5f88\u6602\u8d35\uff09\nvalue = 0\nfor i in range(len(tensor)):\n  value += tensor[i] * tensor[i]\nvalue\n</code></pre> <pre><code>CPU times: user 773 \u00b5s, sys: 0 ns, total: 773 \u00b5s\nWall time: 499 \u00b5s\n</code></pre> <pre><code>%%time\n# \u4f7f\u7528 torch.matmul() \u6267\u884c\u77e9\u9635\u4e58\u6cd5\ntorch.matmul(tensor, tensor)\n</code></pre> <pre><code>CPU times: user 146 \u00b5s, sys: 83 \u00b5s, total: 229 \u00b5s\nWall time: 171 \u00b5s\n</code></pre> <pre><code>tensor(14)\n</code></pre> <p>PyTorch \u5c06\u8fd9\u4e24\u4e2a\u4e00\u7ef4\u5f20\u91cf\u89c6\u4e3a\u5217\u5411\u91cf\u548c\u884c\u5411\u91cf\u3002\u5b83\u4f1a\u81ea\u52a8\u5c06\u5176\u4e2d\u4e00\u4e2a\u5f20\u91cf\u8f6c\u6362\u4e3a\u5217\u5411\u91cf\uff08n x 1\uff09\uff0c\u53e6\u4e00\u4e2a\u8f6c\u6362\u4e3a\u884c\u5411\u91cf\uff081 x n\uff09\uff0c\u7136\u540e\u8fdb\u884c\u77e9\u9635\u4e58\u6cd5\u3002</p>"},{"location":"tutorials/00_pytorch_fundamentals/#_10","title":"\u5f62\u72b6\u5fc5\u987b\u6b63\u786e","text":""},{"location":"tutorials/00_pytorch_fundamentals/#_11","title":"\u6df1\u5ea6\u5b66\u4e60\u4e2d\u6700\u5e38\u89c1\u7684\u9519\u8bef\uff08\u5f62\u72b6\u9519\u8bef\uff09","text":"<p>\u7531\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u5927\u90e8\u5206\u5de5\u4f5c\u6d89\u53ca\u77e9\u9635\u7684\u4e58\u6cd5\u548c\u64cd\u4f5c\uff0c\u5e76\u4e14\u77e9\u9635\u5bf9\u4e8e\u53ef\u4ee5\u7ec4\u5408\u7684\u5f62\u72b6\u548c\u5927\u5c0f\u6709\u4e25\u683c\u7684\u89c4\u5219\uff0c\u6240\u4ee5\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\uff0c\u4f60\u6700\u5e38\u9047\u5230\u7684\u9519\u8bef\u4e4b\u4e00\u5c31\u662f\u5f62\u72b6\u4e0d\u5339\u914d\u3002</p> <pre><code># \u5f62\u72b6\u5fc5\u987b\u6b63\u786e  \ntensor_A = torch.tensor([[1, 2],\n                         [3, 4],\n                         [5, 6]], dtype=torch.float32)\n\ntensor_B = torch.tensor([[7, 10],\n                         [8, 11], \n                         [9, 12]], dtype=torch.float32)\n\ntorch.matmul(tensor_A, tensor_B) # (this will error)\n</code></pre> <pre><code>---------------------------------------------------------------------------\n\nRuntimeError                              Traceback (most recent call last)\n\n/home/daniel/code/pytorch/pytorch-course/pytorch-deep-learning/00_pytorch_fundamentals.ipynb Cell 75 in &lt;cell line: 10&gt;()\n      &lt;a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22544954414e2d525458227d/home/daniel/code/pytorch/pytorch-course/pytorch-deep-learning/00_pytorch_fundamentals.ipynb#Y134sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'&gt;2&lt;/a&gt; tensor_A = torch.tensor([[1, 2],\n      &lt;a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22544954414e2d525458227d/home/daniel/code/pytorch/pytorch-course/pytorch-deep-learning/00_pytorch_fundamentals.ipynb#Y134sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'&gt;3&lt;/a&gt;                          [3, 4],\n      &lt;a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22544954414e2d525458227d/home/daniel/code/pytorch/pytorch-course/pytorch-deep-learning/00_pytorch_fundamentals.ipynb#Y134sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'&gt;4&lt;/a&gt;                          [5, 6]], dtype=torch.float32)\n      &lt;a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22544954414e2d525458227d/home/daniel/code/pytorch/pytorch-course/pytorch-deep-learning/00_pytorch_fundamentals.ipynb#Y134sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'&gt;6&lt;/a&gt; tensor_B = torch.tensor([[7, 10],\n      &lt;a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22544954414e2d525458227d/home/daniel/code/pytorch/pytorch-course/pytorch-deep-learning/00_pytorch_fundamentals.ipynb#Y134sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'&gt;7&lt;/a&gt;                          [8, 11], \n      &lt;a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22544954414e2d525458227d/home/daniel/code/pytorch/pytorch-course/pytorch-deep-learning/00_pytorch_fundamentals.ipynb#Y134sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'&gt;8&lt;/a&gt;                          [9, 12]], dtype=torch.float32)\n---&gt; &lt;a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22544954414e2d525458227d/home/daniel/code/pytorch/pytorch-course/pytorch-deep-learning/00_pytorch_fundamentals.ipynb#Y134sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'&gt;10&lt;/a&gt; torch.matmul(tensor_A, tensor_B)\n\n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)\n</code></pre> <p>\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u4f7f<code>tensor_A</code>\u548c<code>tensor_B</code>\u7684\u5185\u90e8\u7ef4\u5ea6\u5339\u914d\u6765\u5b9e\u73b0\u77e9\u9635\u4e58\u6cd5\u3002</p> <p>\u5176\u4e2d\u4e00\u79cd\u65b9\u6cd5\u662f\u4f7f\u7528\u8f6c\u7f6e\uff08\u4ea4\u6362\u7ed9\u5b9a\u5f20\u91cf\u7684\u7ef4\u5ea6\uff09\u3002</p> <p>\u60a8\u53ef\u4ee5\u4f7f\u7528PyTorch\u6267\u884c\u8f6c\u7f6e\uff0c\u65b9\u6cd5\u6709\u4e24\u79cd\uff1a</p> <ul> <li><code>torch.transpose(input, dim0, dim1)</code> - \u5176\u4e2d<code>input</code>\u662f\u8981\u8f6c\u7f6e\u7684\u76ee\u6807\u5f20\u91cf\uff0c<code>dim0</code>\u548c<code>dim1</code>\u662f\u8981\u4ea4\u6362\u7684\u7ef4\u5ea6\u3002</li> <li><code>tensor.T</code> - \u5176\u4e2d<code>tensor</code>\u662f\u8981\u8f6c\u7f6e\u7684\u76ee\u6807\u5f20\u91cf\u3002</li> </ul> <p>\u8ba9\u6211\u4eec\u5c1d\u8bd5\u540e\u8005\u3002</p> <pre><code># \u67e5\u770btensor_A\u548ctensor_B\nprint(tensor_A)\nprint(tensor_B)\n</code></pre> <pre><code>tensor([[1., 2.],\n        [3., 4.],\n        [5., 6.]])\ntensor([[ 7., 10.],\n        [ 8., 11.],\n        [ 9., 12.]])\n</code></pre> <pre><code># \u67e5\u770btensor_A\u548ctensor_B.T\nprint(tensor_A)\nprint(tensor_B.T)\n</code></pre> <pre><code>tensor([[1., 2.],\n        [3., 4.],\n        [5., 6.]])\ntensor([[ 7.,  8.,  9.],\n        [10., 11., 12.]])\n</code></pre> <pre><code># \u5f53tensor_B\u88ab\u8f6c\u7f6e\u65f6\uff0c\u64cd\u4f5c\u751f\u6548\nprint(f\"\u539f\u59cb\u5f62\u72b6\uff1atensor_A = {tensor_A.shape}\uff0ctensor_B = {tensor_B.shape}\\n\")\nprint(f\"\u65b0\u5f62\u72b6\uff1atensor_A = {tensor_A.shape}\uff08\u4e0e\u4e0a\u9762\u76f8\u540c\uff09\uff0ctensor_B.T = {tensor_B.T.shape}\\n\")\nprint(f\"\u76f8\u4e58\uff1a{tensor_A.shape} * {tensor_B.T.shape} &lt;- \u5185\u90e8\u7ef4\u5ea6\u5339\u914d\\n\")\nprint(\"\u8f93\u51fa\uff1a\\n\")\noutput = torch.matmul(tensor_A, tensor_B.T)\nprint(output) \nprint(f\"\\n\u8f93\u51fa\u5f62\u72b6\uff1a{output.shape}\")\n</code></pre> <pre><code>\u539f\u59cb\u5f62\u72b6\uff1atensor_A = torch.Size([3, 2])\uff0ctensor_B = torch.Size([3, 2])\n\n\u65b0\u5f62\u72b6\uff1atensor_A = torch.Size([3, 2])\uff08\u4e0e\u4e0a\u9762\u76f8\u540c\uff09\uff0ctensor_B.T = torch.Size([2, 3])\n\n\u76f8\u4e58\uff1atorch.Size([3, 2]) * torch.Size([2, 3]) &lt;- \u5185\u90e8\u7ef4\u5ea6\u5339\u914d\n\n\u8f93\u51fa\uff1a\n\ntensor([[ 27.,  30.,  33.],\n        [ 61.,  68.,  75.],\n        [ 95., 106., 117.]])\n\n\u8f93\u51fa\u5f62\u72b6\uff1atorch.Size([3, 3])\n</code></pre> <p>\u60a8\u8fd8\u53ef\u4ee5\u4f7f\u7528<code>torch.mm()</code>\uff0c\u5b83\u662f<code>torch.matmul()</code>\u7684\u7f29\u5199\u3002</p> <pre><code># torch.mm\u662ftorch.matmul()\u7684\u7f29\u5199\ntorch.mm(tensor_A, tensor_B.T)\n</code></pre> <pre><code>tensor([[ 27.,  30.,  33.],\n        [ 61.,  68.,  75.],\n        [ 95., 106., 117.]])\n</code></pre> <p>\u5982\u679c\u6ca1\u6709\u8fdb\u884c\u8f6c\u7f6e\uff0c\u5c06\u4e0d\u6ee1\u8db3\u77e9\u9635\u4e58\u6cd5\u7684\u89c4\u5219\uff0c\u4f1a\u51fa\u73b0\u4e0a\u9762\u7684\u9519\u8bef\u3002</p> <p>\u90a3\u4e48\u5982\u4f55\u8fdb\u884c\u53ef\u89c6\u5316\u5462\uff1f</p> <p></p> <p>\u77e9\u9635\u4e58\u6cd5\u53ef\u89c6\u5316\uff1aMatrix Multiplication</p> <p>\u6ce8\u610f\uff1a\u8fd9\u6837\u7684\u77e9\u9635\u4e58\u6cd5\u4e5f\u88ab\u79f0\u4e3a\u4e24\u4e2a\u77e9\u9635\u7684\u70b9\u79ef\u3002</p> <p>\u795e\u7ecf\u7f51\u7edc\u5145\u6ee1\u4e86\u77e9\u9635\u4e58\u6cd5\u548c\u70b9\u79ef\u3002</p> <p><code>torch.nn.Linear()</code>\u6a21\u5757\uff08\u7a0d\u540e\u6211\u4eec\u5c06\u5728\u5b9e\u9645\u64cd\u4f5c\u4e2d\u770b\u5230\u5b83\uff09\uff0c\u4e5f\u79f0\u4e3a\u524d\u9988feed-forward\u5c42\u6216\u5168\u8fde\u63a5fully connected\u5c42\uff0c\u5b9e\u73b0\u4e86\u8f93\u5165<code>x</code>\u548c\u6743\u91cd\u77e9\u9635<code>A</code>\u4e4b\u95f4\u7684\u77e9\u9635\u4e58\u6cd5\u3002</p> \\[ y = x\\cdot{A^T} + b \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li><code>x</code>\u662f\u5c42\u7684\u8f93\u5165\uff08\u6df1\u5ea6\u5b66\u4e60\u662f\u4e00\u5806\u50cf<code>torch.nn.Linear()</code>\u548c\u5176\u4ed6\u5c42\u53e0\u5728\u4e00\u8d77\u7684\u5c42\uff09\u3002</li> <li><code>A</code>\u662f\u7531\u8be5\u5c42\u521b\u5efa\u7684\u6743\u91cd\u77e9\u9635\uff0c\u5b83\u5f00\u59cb\u65f6\u662f\u968f\u673a\u6570\uff0c\u4f1a\u968f\u7740\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u66f4\u597d\u5730\u8868\u793a\u6570\u636e\u4e2d\u7684\u6a21\u5f0fpatterns\u800c\u8c03\u6574\uff08\u8bf7\u6ce8\u610f\"<code>T</code>\"\uff0c\u8fd9\u662f\u56e0\u4e3a\u6743\u91cd\u77e9\u9635\u88ab\u8f6c\u7f6e\uff09\u3002<ul> <li>\u6ce8\u610f\uff1a\u60a8\u53ef\u80fd\u7ecf\u5e38\u770b\u5230\u4f7f\u7528<code>W</code>\u6216\u5176\u4ed6\u5b57\u6bcd\u5982<code>X</code>\u6765\u5c55\u793a\u6743\u91cd\u77e9\u9635\u3002</li> </ul> </li> <li><code>b</code>\u662f\u7528\u4e8e\u7565\u5fae\u504f\u79fboffset\u6743\u91cdweights\u548c\u8f93\u5165\u7684\u504f\u7f6e\u9879bias\u3002</li> <li><code>y</code>\u662f\u8f93\u51fa\uff08\u5bf9\u8f93\u5165\u7684\u5904\u7406\uff0c\u4ee5\u671f\u53d1\u73b0\u5176\u4e2d\u7684\u6a21\u5f0f\uff09\u3002</li> </ul> <p>\u8fd9\u662f\u4e00\u4e2a\u7ebf\u6027\u51fd\u6570\uff08\u60a8\u53ef\u80fd\u5728\u9ad8\u4e2d\u6216\u5176\u4ed6\u5730\u65b9\u89c1\u8fc7\u7c7b\u4f3c\\(y = mx+b\\)\u7684\u4e1c\u897f\uff09\uff0c\u53ef\u4ee5\u7528\u6765\u7ed8\u5236\u4e00\u6761\u76f4\u7ebf\uff01</p> <p>\u8ba9\u6211\u4eec\u5c1d\u8bd5\u4f7f\u7528\u7ebf\u6027\u5c42\u8fdb\u884c\u4e00\u4e9b\u64cd\u4f5c\u3002</p> <p>\u5c1d\u8bd5\u66f4\u6539<code>in_features</code>\u548c<code>out_features</code>\u7684\u503c\uff0c\u770b\u770b\u4f1a\u53d1\u751f\u4ec0\u4e48\u3002</p> <p>\u662f\u5426\u6ce8\u610f\u5230\u4e0e\u5f62\u72b6\u6709\u5173\u7684\u95ee\u9898\uff1f</p> <pre><code># \u7531\u4e8e\u7ebf\u6027\u5c42\u4ece\u4e00\u4e2a\u968f\u673a\u7684\u6743\u91cd\u77e9\u9635\u5f00\u59cb\uff0c\u8ba9\u6211\u4eec\u4f7f\u5176\u53ef\u590d\u73b0\ntorch.manual_seed(42)\n# \u8fd9\u4f7f\u7528\u4e86\u77e9\u9635\u4e58\u6cd5\nlinear = torch.nn.Linear(in_features=2, # in_features = \u5339\u914d\u8f93\u5165\u7684\u5185\u90e8\u7ef4\u5ea6 \n                         out_features=6) # out_features = \u63cf\u8ff0\u5916\u90e8\u7ef4\u5ea6 \nx = tensor_A\noutput = linear(x)\nprint(f\"\u8f93\u5165\u5f62\u72b6\uff1a{x.shape}\\n\")\nprint(f\"\u8f93\u51fa:\\n{output}\\n\\n\u8f93\u51fa\u5f62\u72b6\uff1a{output.shape}\")\n</code></pre> <pre><code>\u8f93\u5165\u5f62\u72b6\uff1atorch.Size([3, 2])\n\n\u8f93\u51fa:\ntensor([[2.2368, 1.2292, 0.4714, 0.3864, 0.1309, 0.9838],     \n        [4.4919, 2.1970, 0.4469, 0.5285, 0.3401, 2.4777],\n        [6.7469, 3.1648, 0.4224, 0.6705, 0.5493, 3.9716]],\n       grad_fn=&lt;AddmmBackward0&gt;)\n\n\u8f93\u51fa\u5f62\u72b6\uff1atorch.Size([3, 6])\n</code></pre> <p></p> <p>\u5f53\u60a8\u5f00\u59cb\u6df1\u5165\u7814\u7a76\u795e\u7ecf\u7f51\u7edc\u5c42\u5e76\u6784\u5efa\u81ea\u5df1\u7684\u5c42\u65f6\uff0c\u60a8\u4f1a\u53d1\u73b0\u77e9\u9635\u4e58\u6cd5\u65e0\u5904\u4e0d\u5728\u3002 \u6765\u6e90\uff1a Working Class Deep Learner - by Mark Saroufim (substack.com)</p>"},{"location":"tutorials/00_pytorch_fundamentals/#_12","title":"\u793a\u4f8b","text":"<p>\u5047\u8bbe\u6211\u4eec\u6709\u4e00\u4e2a\u8f93\u5165\u5411\u91cf \\( x \\) \u7684\u7ef4\u5ea6\u4e3a <code>[2]</code>\uff08\u5373\u5b83\u67092\u4e2a\u5143\u7d20\uff09\uff0c\u5e76\u4e14\u6211\u4eec\u60f3\u8981\u901a\u8fc7\u4e00\u4e2a\u7ebf\u6027\u5c42\u5c06\u5b83\u8f6c\u6362\u4e3a\u4e00\u4e2a\u7ef4\u5ea6\u4e3a <code>[3]</code> \u7684\u8f93\u51fa\u5411\u91cf \\( y \\)\u3002\u8fd9\u610f\u5473\u7740\u6211\u4eec\u7684\u7ebf\u6027\u5c42\u9700\u8981\u6709\u4e00\u4e2a <code>2x3</code> \u7684\u6743\u91cd\u77e9\u9635 \\( A \\) \u548c\u4e00\u4e2a\u7ef4\u5ea6\u4e3a <code>[3]</code> \u7684\u504f\u7f6e\u5411\u91cf \\( b \\)\u3002</p>"},{"location":"tutorials/00_pytorch_fundamentals/#_13","title":"\u4ee3\u7801\u5b9e\u73b0","text":"<ol> <li>\u5b9a\u4e49\u5c42: \u6211\u4eec\u9996\u5148\u5b9a\u4e49\u4e00\u4e2a <code>torch.nn.Linear(2, 3)</code> \u7684\u5c42\u3002\u8fd9\u91cc\u7684 <code>2</code> \u662f\u8f93\u5165\u7279\u5f81\u7684\u6570\u91cf\uff0c\u800c <code>3</code> \u662f\u8f93\u51fa\u7279\u5f81\u7684\u6570\u91cf\u3002</li> </ol> <pre><code>import torch\nlinear_layer = torch.nn.Linear(2, 3)\n</code></pre> <ol> <li>\u521d\u59cb\u5316\u8f93\u5165: \u63a5\u7740\uff0c\u6211\u4eec\u521b\u5efa\u4e00\u4e2a\u5927\u5c0f\u4e3a <code>[2]</code> \u7684\u8f93\u5165\u5411\u91cf\u3002</li> </ol> <pre><code>x = torch.tensor([1.0, 2.0])\n</code></pre> <ol> <li>\u8fdb\u884c\u524d\u5411\u4f20\u64ad: \u6700\u540e\uff0c\u6211\u4eec\u901a\u8fc7\u8fd9\u4e2a\u5c42\u4f20\u9012\u8f93\u5165 <code>x</code>\u3002</li> </ol> <pre><code>y = linear_layer(x)\n</code></pre> <p>\u5728\u8fd9\u4e2a\u4f8b\u5b50\u4e2d\uff0c<code>linear_layer(x)</code> \u5b9e\u9645\u4e0a\u6267\u884c\u4e86 \\( $x \\cdot A^T + b$ \\) \u7684\u8ba1\u7b97\uff0c\u5176\u4e2d \\(A\\) \u548c \\(b\\)  \u662f\u5c42\u7684\u5185\u90e8\u53c2\u6570\u3002</p>"},{"location":"tutorials/00_pytorch_fundamentals/#_14","title":"\u8f93\u51fa\u7ed3\u679c","text":"<p>\u8f93\u51fa <code>y</code> \u662f\u4e00\u4e2a\u7ef4\u5ea6\u4e3a <code>[3]</code> \u7684\u5f20\u91cf\uff0c\u5b83\u662f\u8f93\u5165 <code>x</code> \u7ecf\u8fc7\u7ebf\u6027\u53d8\u6362\u540e\u7684\u7ed3\u679c\u3002</p> <p>\u8fd9\u4e2a\u8fc7\u7a0b\u5c31\u662f <code>torch.nn.Linear</code> \u6a21\u5757\u7684\u57fa\u672c\u5de5\u4f5c\u65b9\u5f0f\u3002\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u8fd9\u4e2a\u6a21\u5757\u901a\u5e38\u88ab\u7528\u5728\u795e\u7ecf\u7f51\u7edc\u7684\u6784\u5efa\u4e2d\uff0c\u4f5c\u4e3a\u7f51\u7edc\u7684\u4e00\u90e8\u5206\u6765\u5b66\u4e60\u8f93\u5165\u6570\u636e\u5230\u8f93\u51fa\u6570\u636e\u4e4b\u95f4\u7684\u6620\u5c04\u5173\u7cfb\u3002</p>"},{"location":"tutorials/00_pytorch_fundamentals/#aggregation","title":"\u67e5\u627e\u6700\u5c0f\u503c\u3001\u6700\u5927\u503c\u3001\u5e73\u5747\u503c\u3001\u603b\u548c\u7b49\uff08\u805a\u5408aggregation\uff09","text":"<p>\u73b0\u5728\u6211\u4eec\u5df2\u7ecf\u770b\u5230\u4e86\u4e00\u4e9b\u64cd\u4f5c\u5f20\u91cf\u7684\u65b9\u6cd5\uff0c\u8ba9\u6211\u4eec\u8fd0\u884c\u4e00\u4e9b\u805a\u5408\u64cd\u4f5c\uff0c\u5c06\u5176\u4ece\u66f4\u591a\u7684\u503c\u8f6c\u5316\u4e3a\u66f4\u5c11\u7684\u503c\u3002</p> <p>\u9996\u5148\uff0c\u6211\u4eec\u5c06\u521b\u5efa\u4e00\u4e2a\u5f20\u91cf\uff0c\u7136\u540e\u627e\u5230\u5b83\u7684\u6700\u5927\u503c\u3001\u6700\u5c0f\u503c\u3001\u5e73\u5747\u503c\u548c\u603b\u548c\u3002</p> <pre><code># \u521b\u5efa\u4e00\u4e2a\u5f20\u91cf\nx = torch.arange(0, 100, 10)\nx\n</code></pre> <pre><code>tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n</code></pre> <p>\u73b0\u5728\u8ba9\u6211\u4eec\u6267\u884c\u4e00\u4e9b\u805a\u5408\u64cd\u4f5c\u3002</p> <pre><code>print(f\"\u6700\u5c0f\u503c: {x.min()}\")\nprint(f\"\u6700\u5927\u503c: {x.max()}\")\n# print(f\"\u5e73\u5747\u503c: {x.mean()}\") # \u8fd9\u4f1a\u5bfc\u81f4\u9519\u8bef\nprint(f\"\u5e73\u5747\u503c: {x.type(torch.float32).mean()}\") # \u6ca1\u6709float\u6570\u636e\u7c7b\u578b\u5c06\u65e0\u6cd5\u751f\u6548\nprint(f\"\u603b\u548c: {x.sum()}\")\n</code></pre> <pre><code>\u6700\u5c0f\u503c: 0\n\u6700\u5927\u503c: 90\n\u5e73\u5747\u503c: 45.0\n\u603b\u548c: 450\n</code></pre> <p>\u6ce8\u610f\uff1a<code>torch.mean()</code>\uff0c\u8981\u6c42\u5f20\u91cf\u662ffloat\u6570\u636e\u7c7b\u578b\u7684\uff0c\u5426\u5219\u64cd\u4f5c\u5c06\u5931\u8d25\u3002</p> <p>\u60a8\u8fd8\u53ef\u4ee5\u4f7f\u7528<code>torch</code>\u65b9\u6cd5\u6267\u884c\u76f8\u540c\u7684\u64cd\u4f5c\u3002</p> <pre><code>torch.max(x), torch.min(x), torch.mean(x.type(torch.float32)), torch.sum(x)\n</code></pre> <pre><code>(tensor(90), tensor(0), tensor(45.), tensor(450))\n</code></pre>"},{"location":"tutorials/00_pytorch_fundamentals/#_15","title":"\u6700\u5c0f/\u6700\u5927\u503c\u7684\u4f4d\u7f6e\u7d22\u5f15","text":"<p>\u60a8\u8fd8\u53ef\u4ee5\u4f7f\u7528<code>torch.argmax()</code>\u548c<code>torch.argmin()</code>\u6765\u627e\u5230\u5f20\u91cf\u4e2d\u7684\u6700\u5927\u503c\u6216\u6700\u5c0f\u503c\u53d1\u751f\u7684\u7d22\u5f15\u3002\u8fd9\u5bf9\u4e8e\u4ec5\u60f3\u8981\u6700\u9ad8\uff08\u6216\u6700\u4f4e\uff09\u503c\u53d1\u751f\u7684\u4f4d\u7f6e\u800c\u4e0d\u662f\u5b9e\u9645\u503c\u672c\u8eab\u7684\u60c5\u51b5\u5f88\u6709\u5e2e\u52a9\uff08\u6211\u4eec\u5c06\u5728\u7a0d\u540e\u7684\u90e8\u5206\u4e2d\u4f7f\u7528softmax\u6fc0\u6d3b\u51fd\u6570\u65f6\u770b\u5230\u8fd9\u4e00\u70b9\uff09\u3002</p> <pre><code># \u521b\u5efa\u4e00\u4e2a\u5f20\u91cf\ntensor = torch.arange(10, 100, 10)\nprint(f\"\u5f20\u91cf: {tensor}\")\n\n# \u8fd4\u56de\u6700\u5927\u503c\u548c\u6700\u5c0f\u503c\u7684\u7d22\u5f15\nprint(f\"\u6700\u5927\u503c\u7684\u7d22\u5f15: {tensor.argmax()}\")\nprint(f\"\u6700\u5c0f\u503c\u7684\u7d22\u5f15: {tensor.argmin()}\")\n</code></pre> <pre><code>\u5f20\u91cf: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n\u6700\u5927\u503c\u7684\u7d22\u5f15: 8\n\u6700\u5c0f\u503c\u7684\u7d22\u5f15: 0\n</code></pre>"},{"location":"tutorials/00_pytorch_fundamentals/#_16","title":"\u66f4\u6539\u5f20\u91cf\u6570\u636e\u7c7b\u578b","text":"<p>\u6b63\u5982\u524d\u9762\u6240\u63d0\u5230\u7684\uff0c\u6df1\u5ea6\u5b66\u4e60\u64cd\u4f5c\u7684\u4e00\u4e2a\u5e38\u89c1\u95ee\u9898\u662f\u60a8\u7684\u5f20\u91cf\u5177\u6709\u4e0d\u540c\u7684\u6570\u636e\u7c7b\u578b\u3002</p> <p>\u5982\u679c\u4e00\u4e2a\u5f20\u91cf\u662f<code>torch.float64</code>\uff0c\u800c\u53e6\u4e00\u4e2a\u662f<code>torch.float32</code>\uff0c\u60a8\u53ef\u80fd\u4f1a\u9047\u5230\u4e00\u4e9b\u9519\u8bef\u3002</p> <p>\u4f46\u662f\u6709\u89e3\u51b3\u65b9\u6cd5\u3002</p> <p>\u60a8\u53ef\u4ee5\u4f7f\u7528<code>torch.Tensor.type(dtype=None)</code>\uff0c\u5176\u4e2d<code>dtype</code>\u53c2\u6570\u662f\u60a8\u60f3\u8981\u4f7f\u7528\u7684\u6570\u636e\u7c7b\u578b\u3002</p> <p>\u9996\u5148\uff0c\u6211\u4eec\u5c06\u521b\u5efa\u4e00\u4e2a\u5f20\u91cf\u5e76\u68c0\u67e5\u5176\u6570\u636e\u7c7b\u578b\uff08\u9ed8\u8ba4\u4e3a<code>torch.float32</code>\uff09\u3002</p> <pre><code># \u521b\u5efa\u4e00\u4e2a\u5f20\u91cf\u5e76\u68c0\u67e5\u5176\u6570\u636e\u7c7b\u578b\ntensor = torch.arange(10., 100., 10.)\ntensor.dtype\n</code></pre> <pre><code>torch.float32\n</code></pre> <p>\u73b0\u5728\uff0c\u6211\u4eec\u5c06\u521b\u5efa\u53e6\u4e00\u4e2a\u4e0e\u524d\u9762\u76f8\u540c\u7684\u5f20\u91cf\uff0c\u4f46\u5c06\u5176\u6570\u636e\u7c7b\u578b\u66f4\u6539\u4e3a<code>torch.float16</code>\u3002</p> <pre><code># \u521b\u5efa\u4e00\u4e2afloat16\u5f20\u91cf\ntensor_float16 = tensor.type(torch.float16)\ntensor_float16\n</code></pre> <pre><code>tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)\n</code></pre> <p>\u6211\u4eec\u4e5f\u53ef\u4ee5\u4f7f\u7528<code>torch.int8</code>\u5f20\u91cf\u8fdb\u884c\u7c7b\u4f3c\u64cd\u4f5c\u3002</p> <pre><code># \u521b\u5efa\u4e00\u4e2aint8\u5f20\u91cf\ntensor_int8 = tensor.type(torch.int8)\ntensor_int8\n</code></pre> <pre><code>tensor([10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8)\n</code></pre> <p>\u6ce8\u610f\uff1a\u4e0d\u540c\u7684\u6570\u636e\u7c7b\u578b\u53ef\u80fd\u4e00\u5f00\u59cb\u4f1a\u8ba9\u4eba\u611f\u5230\u56f0\u60d1\u3002\u4f46\u53ef\u4ee5\u8fd9\u6837\u8003\u8651\uff0c\u6570\u5b57\u8d8a\u4f4e\uff08\u4f8b\u598232\u300116\u30018\uff09\uff0c\u8ba1\u7b97\u673a\u5b58\u50a8\u8be5\u503c\u7684\u7cbe\u5ea6\u5c31\u8d8a\u4f4e\u3002\u5e76\u4e14\u968f\u7740\u5b58\u50a8\u91cf\u51cf\u5c11\uff0c\u901a\u5e38\u4f1a\u5bfc\u81f4\u66f4\u5feb\u7684\u8ba1\u7b97\u901f\u5ea6\u548c\u66f4\u5c0f\u7684\u603b\u6a21\u578b\u5927\u5c0f\u3002\u57fa\u4e8e\u79fb\u52a8\u8bbe\u5907\u7684\u795e\u7ecf\u7f51\u7edc\u901a\u5e38\u4f7f\u75288\u4f4d\u6574\u6570\uff0c\u6bd4\u5176float32\u5bf9\u5e94\u9879\u7cbe\u5ea6\u8f83\u4f4e\uff0c\u4f46\u8fd0\u884c\u901f\u5ea6\u66f4\u5feb\u3002\u6709\u5173\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u9605\u8bfb\u8ba1\u7b97\u4e2d\u7684\u7cbe\u5ea6\u3002</p> <p>\u53c2\u8003\uff1a<code>torch.Tensor</code>\u6587\u6863</p>"},{"location":"tutorials/00_pytorch_fundamentals/#reshapingstackingsqueezingunsqueezing","title":"\u91cd\u5851reshaping\u3001\u5806\u53e0stacking\u3001\u6324\u538bsqueezing\u548c\u5c55\u5f00unsqueezing","text":"<p>\u901a\u5e38\uff0c\u60a8\u4f1a\u5e0c\u671b\u91cd\u5851\u6216\u66f4\u6539\u5f20\u91cf\u7684\u7ef4\u5ea6\uff0c\u800c\u4e0d\u5b9e\u9645\u66f4\u6539\u5176\u4e2d\u7684\u503c\u3002</p> <p>\u4e3a\u6b64\uff0c\u4e00\u4e9b\u5e38\u7528\u7684\u65b9\u6cd5\u5305\u62ec\uff1a</p> \u65b9\u6cd5 \u4e00\u53e5\u8bdd\u63cf\u8ff0 <code>torch.reshape(input, shape)</code> \u91cd\u5851<code>input</code>\u4e3a<code>shape</code>\uff08\u5982\u679c\u517c\u5bb9\uff09\uff0c\u4e5f\u53ef\u4ee5\u4f7f\u7528<code>torch.Tensor.reshape()</code>\u3002 <code>Tensor.view(shape)</code> \u8fd4\u56de\u539f\u59cb\u5f20\u91cf\u7684\u5177\u6709\u4e0d\u540c<code>shape</code>\u7684\u89c6\u56fe\uff0c\u4f46\u4e0e\u539f\u59cb\u5f20\u91cf\u5171\u4eab\u76f8\u540c\u7684\u6570\u636e\u3002 <code>torch.stack(tensors, dim=0)</code> \u6cbf\u65b0\u7ef4\u5ea6\uff08<code>dim</code>\uff09\u8fde\u63a5\u4e00\u7cfb\u5217<code>tensors</code>\uff0c\u6240\u6709<code>tensors</code>\u7684\u5927\u5c0f\u5fc5\u987b\u76f8\u540c\u3002 <code>torch.squeeze(input)</code> \u6324\u538b<code>input</code>\u4ee5\u5220\u9664\u6240\u6709\u503c\u4e3a<code>1</code>\u7684\u7ef4\u5ea6\u3002 <code>torch.unsqueeze(input, dim)</code> \u5728<code>dim</code>\u5904\u6dfb\u52a0\u503c\u4e3a<code>1</code>\u7684\u7ef4\u5ea6\u5230<code>input</code>\u4e2d\u3002 <code>torch.permute(input, dims)</code> \u8fd4\u56de\u539f\u59cb<code>input</code>\u7684\u89c6\u56fe\uff0c\u5176\u7ef4\u5ea6\u88ab\u91cd\u65b0\u6392\u5217\u4e3a<code>dims</code>\u3002 <p>\u4e3a\u4ec0\u4e48\u8981\u4f7f\u7528\u8fd9\u4e9b\u65b9\u6cd5\uff1f</p> <p>\u56e0\u4e3a\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff08\u795e\u7ecf\u7f51\u7edc\uff09\u90fd\u662f\u5173\u4e8e\u4ee5\u67d0\u79cd\u65b9\u5f0f\u64cd\u4f5c\u5f20\u91cf\u3002\u7531\u4e8e\u77e9\u9635\u4e58\u6cd5\u7684\u89c4\u5219\uff0c\u5982\u679c\u7ef4\u5ea6\u4e0d\u5339\u914d\uff0c\u60a8\u5c06\u9047\u5230\u9519\u8bef\u3002\u8fd9\u4e9b\u65b9\u6cd5\u5e2e\u52a9\u60a8\u786e\u4fdd\u5f20\u91cf\u7684\u6b63\u786e\u5143\u7d20\u4e0e\u5176\u4ed6\u5f20\u91cf\u7684\u6b63\u786e\u5143\u7d20\u6df7\u5408\u3002</p> <p>\u8ba9\u6211\u4eec\u6765\u8bd5\u8bd5\u3002</p> <p>\u9996\u5148\uff0c\u6211\u4eec\u5c06\u521b\u5efa\u4e00\u4e2a\u5f20\u91cf\u3002</p> <pre><code># \u521b\u5efa\u4e00\u4e2a\u5f20\u91cf\nimport torch\nx = torch.arange(1., 8.)\nx, x.shape\n</code></pre> <pre><code>(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))\n</code></pre> <p>\u73b0\u5728\u8ba9\u6211\u4eec\u4f7f\u7528<code>torch.reshape()</code>\u6dfb\u52a0\u4e00\u4e2a\u989d\u5916\u7684\u7ef4\u5ea6\u3002</p> <pre><code># \u6dfb\u52a0\u4e00\u4e2a\u989d\u5916\u7684\u7ef4\u5ea6\nx_reshaped = x.reshape(1, 7)\nx_reshaped, x_reshaped.shape\n</code></pre> <pre><code>(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))\n</code></pre> <p>\u6211\u4eec\u8fd8\u53ef\u4ee5\u4f7f\u7528<code>torch.view()</code>\u6539\u53d8\u89c6\u56fe\u3002</p> <pre><code># \u66f4\u6539\u89c6\u56fe\uff08\u4fdd\u6301\u4e0e\u539f\u59cb\u6570\u636e\u76f8\u540c\u4f46\u66f4\u6539\u89c6\u56fe\uff09\n# \u4e86\u89e3\u66f4\u591a\uff1ahttps://stackoverflow.com/a/54507446/7900723\nz = x.view(1, 7)\nz, z.shape\n</code></pre> <pre><code>(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))\n</code></pre> <p>\u8bf7\u8bb0\u4f4f\uff0c\u4f7f\u7528<code>torch.view()</code>\u66f4\u6539\u5f20\u91cf\u7684\u89c6\u56fe\u5b9e\u9645\u4e0a\u53ea\u4f1a\u521b\u5efa\u76f8\u540c\u5f20\u91cf\u7684\u65b0\u89c6\u56fe\u3002</p> <p>\u56e0\u6b64\uff0c\u66f4\u6539\u89c6\u56fe\u4f1a\u66f4\u6539\u539f\u59cb\u5f20\u91cf\u3002</p> <pre><code># \u66f4\u6539z\u4f1a\u66f4\u6539x\nz[:, 0] = 5\nz, x\n</code></pre> <pre><code>(tensor([[5., 2., 3., 4., 5., 6., 7.]]), tensor([5., 2., 3., 4., 5., 6., 7.]))\n</code></pre> <p>\u5982\u679c\u6211\u4eec\u60f3\u5c06\u65b0\u5f20\u91cf\u5806\u53e0\u5728\u81ea\u8eab\u4e0a\u4e94\u6b21\uff0c\u53ef\u4ee5\u4f7f\u7528<code>torch.stack()</code>\u3002</p> <pre><code># \u5806\u53e0\u5f20\u91cf\u5728\u4e00\u8d77\nx_stacked = torch.stack([x, x, x, x], dim=0) \nx_stacked\n</code></pre> <pre><code>tensor([[5., 2., 3., 4., 5., 6., 7.],\n        [5., 2., 3., 4., 5., 6., 7.],\n        [5., 2., 3., 4., 5., 6., 7.],\n        [5., 2., 3., 4., 5., 6., 7.]])\n</code></pre> <pre><code>x_stacked = torch.stack([x, x, x, x], dim=1) \nx_stacked\n</code></pre> <pre><code>tensor([[5., 5., 5., 5.],\n        [2., 2., 2., 2.],\n        [3., 3., 3., 3.],\n        [4., 4., 4., 4.],\n        [5., 5., 5., 5.],\n        [6., 6., 6., 6.],\n        [7., 7., 7., 7.]])\n</code></pre> <p><code>dim</code> \u53c2\u6570\u51b3\u5b9a\u4e86\u65b0\u7ef4\u5ea6\u7684\u4f4d\u7f6e\u3002\u4f8b\u5982\uff0c\u5982\u679c <code>dim=0</code>\uff0c\u65b0\u7ef4\u5ea6\u5c06\u88ab\u6dfb\u52a0\u5230\u6700\u524d\u9762\uff1b\u5982\u679c <code>dim=1</code>\uff0c\u5219\u65b0\u7ef4\u5ea6\u5c06\u88ab\u63d2\u5165\u5230\u7b2c\u4e8c\u7684\u4f4d\u7f6e\uff0c\u4f9d\u6b64\u7c7b\u63a8\u3002</p> <p>\u5982\u4f55\u4ece\u5f20\u91cf\u4e2d\u5220\u9664\u6240\u6709\u5355\u7ef4\u5ea6\uff1f</p> <p>\u4e3a\u6b64\uff0c\u60a8\u53ef\u4ee5\u4f7f\u7528<code>torch.squeeze()</code>\uff08\u6324\u538b\u5f20\u91cf\uff0c\u53ea\u4fdd\u7559\u7ef4\u5ea6\u5927\u4e8e1\u7684\u7ef4\u5ea6\uff09\u3002</p> <pre><code>print(f\"\u4ee5\u524d\u7684\u5f20\u91cf\uff1a{x_reshaped}\")\nprint(f\"\u4ee5\u524d\u7684\u5f62\u72b6\uff1a{x_reshaped.shape}\")\n\n# \u4ecex_reshaped\u4e2d\u5220\u9664\u989d\u5916\u7684\u7ef4\u5ea6\nx_squeezed = x_reshaped.squeeze()\nprint(f\"\\n\u65b0\u5f20\u91cf\uff1a{x_squeezed}\")\nprint(f\"\u65b0\u5f62\u72b6\uff1a{x_squeezed.shape}\")\n</code></pre> <pre><code>Previous tensor: tensor([[5., 2., 3., 4., 5., 6., 7.]])\nPrevious shape: torch.Size([1, 7])\n\nNew tensor: tensor([5., 2., 3., 4., 5., 6., 7.])\nNew shape: torch.Size([7])\n</code></pre> <p>\u8981\u6267\u884c<code>torch.squeeze()</code>\u7684\u53cd\u64cd\u4f5c\uff0c\u60a8\u53ef\u4ee5\u4f7f\u7528<code>torch.unsqueeze()</code>\u5728\u7279\u5b9a\u7d22\u5f15\u5904\u6dfb\u52a0\u503c\u4e3a1\u7684\u7ef4\u5ea6\u3002</p> <pre><code>print(f\"\u4ee5\u524d\u7684\u5f20\u91cf\uff1a{x_squeezed}\")\nprint(f\"\u4ee5\u524d\u7684\u5f62\u72b6\uff1a{x_squeezed.shape}\")\n\n## \u4f7f\u7528unsqueeze\u6dfb\u52a0\u989d\u5916\u7684\u7ef4\u5ea6\nx_unsqueezed = x_squeezed.unsqueeze(dim=0)\nprint(f\"\\n\u65b0\u5f20\u91cf\uff1a{x_unsqueezed}\")\nprint(f\"\u65b0\u5f62\u72b6\uff1a{x_unsqueezed.shape}\")\n</code></pre> <pre><code>Previous tensor: tensor([5., 2., 3., 4., 5., 6., 7.])\nPrevious shape: torch.Size([7])\n\nNew tensor: tensor([[5., 2., 3., 4., 5., 6., 7.]])\nNew shape: torch.Size([1, 7])\n</code></pre> <p>\u60a8\u8fd8\u53ef\u4ee5\u4f7f\u7528<code>torch.permute(input, dims)</code>\u91cd\u65b0\u6392\u5217\u8f74\u503c\u7684\u987a\u5e8f\uff0c\u5176\u4e2d<code>input</code>\u53d8\u6210\u4e86\u5177\u6709\u65b0<code>dims</code>\u7684\u89c6\u56fe\u3002</p> <pre><code># \u521b\u5efa\u5177\u6709\u7279\u5b9a\u5f62\u72b6\u7684\u5f20\u91cf\nx_original = torch.rand(size=(224, 224, 3))\n\n# \u5c06\u539f\u59cb\u5f20\u91cf\u91cd\u65b0\u6392\u5217\u4ee5\u91cd\u65b0\u6392\u5217\u8f74\u987a\u5e8f\nx_permuted = x_original.permute(2, 0, 1) # \u5c06\u8f740-&gt;1\uff0c1-&gt;2\uff0c2-&gt;0\nprint(f\"\u4ee5\u524d\u7684\u5f62\u72b6\uff1a{x_original.shape}\")\nprint(f\"\u65b0\u5f62\u72b6\uff1a{x_permuted.shape}\")\n</code></pre> <pre><code>Previous shape: torch.Size([224, 224, 3])\nNew shape: torch.Size([3, 224, 224])\n</code></pre> <p>\u6ce8\u610f\uff1a\u56e0\u4e3a\u91cd\u65b0\u6392\u5217\u8fd4\u56de\u4e00\u4e2a\u89c6\u56fe\uff08\u4e0e\u539f\u59cb\u6570\u636e\u76f8\u540c\uff09\uff0c\u6240\u4ee5\u91cd\u65b0\u6392\u5217\u5f20\u91cf\u4e2d\u7684\u503c\u5c06\u4e0e\u539f\u59cb\u5f20\u91cf\u4e2d\u7684\u503c\u76f8\u540c\uff0c\u5982\u679c\u66f4\u6539\u89c6\u56fe\u4e2d\u7684\u503c\uff0c\u5b83\u5c06\u66f4\u6539\u539f\u59cb\u503c</p>"},{"location":"tutorials/00_pytorch_fundamentals/#_17","title":"\u7d22\u5f15\uff08\u4ece\u5f20\u91cf\u4e2d\u9009\u62e9\u6570\u636e\uff09","text":"<p>\u6709\u65f6\u5019\uff0c\u60a8\u53ef\u80fd\u60f3\u8981\u4ece\u5f20\u91cf\u4e2d\u9009\u62e9\u7279\u5b9a\u7684\u6570\u636e\uff08\u4f8b\u5982\uff0c\u53ea\u9009\u62e9\u7b2c\u4e00\u5217\u6216\u7b2c\u4e8c\u884c\uff09\u3002</p> <p>\u4e3a\u4e86\u505a\u5230\u8fd9\u4e00\u70b9\uff0c\u60a8\u53ef\u4ee5\u4f7f\u7528\u7d22\u5f15\u3002</p> <p>\u5982\u679c\u60a8\u4ee5\u524d\u5728Python\u5217\u8868\u6216NumPy\u6570\u7ec4\u4e0a\u8fdb\u884c\u8fc7\u7d22\u5f15\u64cd\u4f5c\uff0c\u90a3\u4e48\u5728PyTorch\u4e2d\u4f7f\u7528\u5f20\u91cf\u8fdb\u884c\u7d22\u5f15\u64cd\u4f5c\u975e\u5e38\u7c7b\u4f3c\u3002</p> <pre><code># \u521b\u5efa\u4e00\u4e2a\u5f20\u91cf\nimport torch\nx = torch.arange(1, 10).reshape(1, 3, 3)\nx, x.shape\n</code></pre> <pre><code>(tensor([[[1, 2, 3],\n          [4, 5, 6],\n          [7, 8, 9]]]),\n torch.Size([1, 3, 3]))\n</code></pre> <p>\u7d22\u5f15\u503c\u4ece\u5916\u90e8\u7ef4\u5ea6 -&gt; \u5185\u90e8\u7ef4\u5ea6\uff08\u67e5\u770b\u65b9\u62ec\u53f7\uff09\u3002</p> <pre><code># \u8ba9\u6211\u4eec\u9010\u4e2a\u65b9\u62ec\u53f7\u8fdb\u884c\u7d22\u5f15\nprint(f\"\u7b2c\u4e00\u4e2a\u65b9\u62ec\u53f7\uff1a\\n{x[0]}\") \nprint(f\"\u7b2c\u4e8c\u4e2a\u65b9\u62ec\u53f7\uff1a{x[0][0]}\") \nprint(f\"\u7b2c\u4e09\u4e2a\u65b9\u62ec\u53f7\uff1a{x[0][0][0]}\")\n</code></pre> <pre><code>\u7b2c\u4e00\u4e2a\u65b9\u62ec\u53f7\uff1a\ntensor([[1, 2, 3],\n        [4, 5, 6],\n        [7, 8, 9]])\n\u7b2c\u4e8c\u4e2a\u65b9\u62ec\u53f7\uff1atensor([1, 2, 3])\n\u7b2c\u4e09\u4e2a\u65b9\u62ec\u53f7\uff1a1\n</code></pre> <p>\u60a8\u8fd8\u53ef\u4ee5\u4f7f\u7528 <code>:</code> \u6765\u6307\u5b9a \"\u5728\u6b64\u7ef4\u5ea6\u4e2d\u7684\u6240\u6709\u503c\"\uff0c\u7136\u540e\u4f7f\u7528\u9017\u53f7\uff08<code>,</code>\uff09\u6765\u6dfb\u52a0\u53e6\u4e00\u4e2a\u7ef4\u5ea6\u3002</p> <pre><code># \u83b7\u53d6\u7b2c0\u7ef4\u5ea6\u7684\u6240\u6709\u503c\u548c\u7b2c1\u7ef4\u5ea6\u7684\u7d22\u5f150\u7684\u503c\nx[:, 0]\n</code></pre> <pre><code>tensor([[1, 2, 3]])\n</code></pre> <pre><code># \u83b7\u53d6\u7b2c0\u548c\u7b2c1\u7ef4\u5ea6\u7684\u6240\u6709\u503c\uff0c\u4f46\u53ea\u83b7\u53d6\u7b2c2\u7ef4\u5ea6\u7684\u7d22\u5f151\u7684\u503c\nx[:, :, 1]\n</code></pre> <pre><code>tensor([[2, 5, 8]])\n</code></pre> <pre><code># \u83b7\u53d6\u7b2c0\u7ef4\u5ea6\u7684\u6240\u6709\u503c\uff0c\u4f46\u53ea\u83b7\u53d6\u7b2c1\u548c\u7b2c2\u7ef4\u5ea6\u7684\u7d22\u5f151\u7684\u503c\nx[:, 1, 1]\n</code></pre> <pre><code>tensor([5])\n</code></pre> <pre><code># \u83b7\u53d6\u7b2c0\u7ef4\u5ea6\u7684\u7d22\u5f150\u548c\u7b2c1\u7ef4\u5ea6\u7684\u6240\u6709\u503c\nx[0, 0, :] # \u4e0e x[0][0] \u76f8\u540c\n</code></pre> <pre><code>tensor([1, 2, 3])\n</code></pre> <p>\u7d22\u5f15\u53ef\u80fd\u5728\u5f00\u59cb\u65f6\u4f1a\u6709\u4e9b\u4ee4\u4eba\u56f0\u60d1\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u8f83\u5927\u7684\u5f20\u91cf\uff08\u6211\u4ecd\u7136\u9700\u8981\u5c1d\u8bd5\u591a\u6b21\u624d\u80fd\u5f04\u6e05\u695a\uff09\u3002\u4f46\u662f\u901a\u8fc7\u4e00\u4e9b\u7ec3\u4e60\u5e76\u9075\u5faa\u6570\u636e\u63a2\u7d22\u8005\u7684\u683c\u8a00\uff08\u53ef\u89c6\u5316\uff0c\u53ef\u89c6\u5316\uff0c\u53ef\u89c6\u5316\uff09\uff0c\u60a8\u5c06\u5f00\u59cb\u638c\u63e1\u5b83\u3002</p> <p>\u8fd9\u91cc\u5b58\u5728\u4e00\u4e2a\u6bd4\u8f83\u5bb9\u6613\u6df7\u6dc6\u7684\u70b9\uff0c\u5373\u6700\u540e\u7d22\u5f15\u5f97\u5230\u7684\u7ed3\u679c\u6709\u591a\u5c11\u62ec\u53f7</p> <pre><code>import torch\nx = torch.arange(1, 10).reshape(1, 3, 3)\nx, x.shape\n</code></pre> <pre><code>(tensor([[[1, 2, 3],\n          [4, 5, 6],\n          [7, 8, 9]]]),\ntorch.Size([1, 3, 3]))\n</code></pre> <p>\u4e0d\u540c\u7684\u7d22\u5f15\u65b9\u5f0f\uff1a</p> <pre><code>x[: , :, 2]\n</code></pre> <p>tensor([[3, 6, 9]])</p> <pre><code>x[ 0, :, 2]\n</code></pre> <p>tensor([3, 6, 9])</p> <p>\u53ef\u4ee5\u603b\u7ed3\u5f97\u51fa\uff1a</p> <p>\u7d22\u5f15\u7ed3\u679c\u7684<code>[]</code>\u6570+\u7d22\u5f15\u4e2d\u7684\u6570\u5b57\u6570\u91cf=\u603b\u7ef4\u5ea6\u6570</p> <p>\u4e5f\u53ef\u4ee5\u7406\u89e3\u4e3a\uff1a\u7d22\u5f15\u65f6\u6bcf\u4f7f\u7528\u4e00\u4e2a\u786e\u5207\u7684\u6570\u5b57\uff0c\u5f97\u5230\u7684\u7ed3\u679c\u5c11\u4e00\u4e2a\u7ef4\u5ea6<code>[]</code></p> <p>\u6bd4\u5982x[0,2,2]=9\uff0c\u662f0\u7ef4</p>"},{"location":"tutorials/00_pytorch_fundamentals/#pytorchnumpy","title":"PyTorch\u5f20\u91cf\u548cNumPy","text":"<p>\u7531\u4e8eNumPy\u662f\u4e00\u79cd\u6d41\u884c\u7684Python\u6570\u503c\u8ba1\u7b97\u5e93\uff0cPyTorch\u5177\u6709\u4e0e\u4e4b\u826f\u597d\u4e92\u64cd\u4f5c\u7684\u529f\u80fd\u3002</p> <p>\u60a8\u5c06\u60f3\u8981\u4f7f\u7528\u7684\u4e24\u4e2a\u4e3b\u8981\u65b9\u6cd5\u7528\u4e8eNumPy\u5230PyTorch\uff08\u4ee5\u53ca\u53cd\u5411\u64cd\u4f5c\uff09\u662f\uff1a</p> <ul> <li><code>torch.from_numpy(ndarray)</code> - \u5c06NumPy\u6570\u7ec4\u8f6c\u6362\u4e3aPyTorch\u5f20\u91cf\u3002</li> <li><code>torch.Tensor.numpy()</code> - \u5c06PyTorch\u5f20\u91cf\u8f6c\u6362\u4e3aNumPy\u6570\u7ec4\u3002</li> </ul> <p>\u8ba9\u6211\u4eec\u8bd5\u4e00\u8bd5\u3002</p> <pre><code># \u4eceNumPy\u6570\u7ec4\u5230\u5f20\u91cf\nimport torch\nimport numpy as np\narray = np.arange(1.0, 8.0)\ntensor = torch.from_numpy(array)\narray, tensor\n</code></pre> <pre><code>(array([1., 2., 3., 4., 5., 6., 7.]),\n tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))\n</code></pre> <p>\u6ce8\u610f\uff1a \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0cNumPy\u6570\u7ec4\u4f7f\u7528<code>float64</code>\u6570\u636e\u7c7b\u578b\u521b\u5efa\uff0c\u5982\u679c\u60a8\u5c06\u5176\u8f6c\u6362\u4e3aPyTorch\u5f20\u91cf\uff0c\u5b83\u5c06\u4fdd\u6301\u76f8\u540c\u7684\u6570\u636e\u7c7b\u578b\uff08\u5982\u4e0a\u6240\u793a\uff09\u3002</p> <p>\u4f46\u662f\uff0c\u8bb8\u591aPyTorch\u8ba1\u7b97\u9ed8\u8ba4\u4f7f\u7528<code>float32</code>\u3002</p> <p>\u56e0\u6b64\uff0c\u5982\u679c\u60a8\u60f3\u5c06NumPy\u6570\u7ec4\uff08float64\uff09\u8f6c\u6362\u4e3aPyTorch\u5f20\u91cf\uff08float64\uff09\u7136\u540e\u518d\u8f6c\u6362\u4e3aPyTorch\u5f20\u91cf\uff08float32\uff09\uff0c\u60a8\u53ef\u4ee5\u4f7f\u7528<code>tensor = torch.from_numpy(array).type(torch.float32)</code>\u3002</p> <p>\u56e0\u4e3a\u6211\u4eec\u5728\u4e0a\u9762\u91cd\u65b0\u8d4b\u503c\u4e86<code>tensor</code>\uff0c\u6240\u4ee5\u5982\u679c\u60a8\u66f4\u6539\u5f20\u91cf\uff0c\u6570\u7ec4\u4fdd\u6301\u4e0d\u53d8\u3002</p> <pre><code># \u66f4\u6539\u6570\u7ec4\uff0c\u4fdd\u6301\u5f20\u91cf\u4e0d\u53d8\narray = array + 1\narray, tensor\n</code></pre> <pre><code>(array([2., 3., 4., 5., 6., 7., 8.]),\n tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))\n</code></pre> <p>\u5982\u679c\u60a8\u60f3\u4ecePyTorch\u5f20\u91cf\u8f6c\u6362\u4e3aNumPy\u6570\u7ec4\uff0c\u60a8\u53ef\u4ee5\u8c03\u7528<code>tensor.numpy()</code>\u3002</p> <pre><code># \u4ece\u5f20\u91cf\u5230NumPy\u6570\u7ec4\ntensor = torch.ones\n\n(7) # \u521b\u5efa\u4e00\u4e2adtype=float32\u7684\u51681\u5f20\u91cf\nnumpy_tensor = tensor.numpy() # \u9664\u975e\u66f4\u6539\uff0c\u5426\u5219dtype=float32\ntensor, numpy_tensor\n</code></pre> <pre><code>(tensor([1., 1., 1., 1., 1., 1., 1.]),\n array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))\n</code></pre> <p>\u540c\u6837\u7684\u89c4\u5219\u9002\u7528\u4e8e\u4e0a\u9762\u7684\u60c5\u51b5\uff0c\u5982\u679c\u66f4\u6539\u539f\u59cb\u7684<code>tensor</code>\uff0c\u65b0\u7684<code>numpy_tensor</code>\u4fdd\u6301\u4e0d\u53d8\u3002</p> <pre><code># \u66f4\u6539\u5f20\u91cf\uff0c\u4fdd\u6301\u6570\u7ec4\u4e0d\u53d8\ntensor = tensor + 1\ntensor, numpy_tenso\n</code></pre> <pre><code>(tensor([2., 2., 2., 2., 2., 2., 2.]),\n array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))\n</code></pre>"},{"location":"tutorials/00_pytorch_fundamentals/#reproducibility","title":"\u53ef\u590d\u73b0\u6027Reproducibility\uff08\u6d88\u9664\u968f\u673a\u6027\uff09","text":"<p>\u968f\u7740\u60a8\u5bf9\u795e\u7ecf\u7f51\u7edc\u548c\u673a\u5668\u5b66\u4e60\u7684\u4e86\u89e3\u8d8a\u6765\u8d8a\u591a\uff0c\u60a8\u5c06\u5f00\u59cb\u53d1\u73b0\u968f\u673a\u6027\u5728\u5176\u4e2d\u626e\u6f14\u4e86\u591a\u5927\u7684\u89d2\u8272\u3002</p> <p>\u55ef\uff0c\u4f2a\u968f\u673a\u6027\u3002\u56e0\u4e3a\u6bd5\u7adf\uff0c\u6309\u7167\u5b83\u4eec\u7684\u8bbe\u8ba1\uff0c\u8ba1\u7b97\u673a\u57fa\u672c\u4e0a\u662f\u786e\u5b9a\u6027\u7684\uff08\u6bcf\u4e00\u6b65\u90fd\u662f\u53ef\u9884\u6d4b\u7684\uff09\uff0c\u6240\u4ee5\u5b83\u4eec\u751f\u6210\u7684\u968f\u673a\u6027\u662f\u6a21\u62df\u7684\u968f\u673a\u6027\u3002</p> <p>\u8fd9\u4e0e\u795e\u7ecf\u7f51\u7edc\u548c\u6df1\u5ea6\u5b66\u4e60\u6709\u4ec0\u4e48\u5173\u7cfb\u5462\uff1f</p> <p>\u6211\u4eec\u5df2\u7ecf\u8ba8\u8bba\u8fc7\u795e\u7ecf\u7f51\u7edc\u4ece\u968f\u673a\u6570\u5f00\u59cb\u63cf\u8ff0\u6570\u636e\u4e2d\u7684\u6a21\u5f0f\uff08\u8fd9\u4e9b\u6570\u5b57\u63cf\u8ff0\u5f97\u4e0d\u597d\uff09\uff0c\u7136\u540e\u5c1d\u8bd5\u4f7f\u7528\u5f20\u91cf\u64cd\u4f5c\uff08\u4ee5\u53ca\u4e00\u4e9b\u6211\u4eec\u5c1a\u672a\u8ba8\u8bba\u7684\u5176\u4ed6\u4e1c\u897f\uff09\u6765\u66f4\u597d\u5730\u63cf\u8ff0\u6570\u636e\u4e2d\u7684\u6a21\u5f0f\u3002</p> <p>\u7b80\u800c\u8a00\u4e4b\uff1a</p> <p><code>\u4ece\u968f\u673a\u6570\u5f00\u59cb -&gt; \u5f20\u91cf\u64cd\u4f5c -&gt; \u5c1d\u8bd5\u6539\u8fdb\uff08\u4e00\u904d\u53c8\u4e00\u904d\uff09</code></p> <p>\u5c3d\u7ba1\u968f\u673a\u6027\u5f88\u597d\u4e14\u5f3a\u5927\uff0c\u4f46\u6709\u65f6\u60a8\u5e0c\u671b\u968f\u673a\u6027\u8f83\u5c0f\u3002</p> <p>\u4e3a\u4ec0\u4e48\u5462\uff1f</p> <p>\u8fd9\u6837\u60a8\u53ef\u4ee5\u8fdb\u884c\u53ef\u91cd\u590d\u7684\u5b9e\u9a8c\u3002</p> <p>\u4f8b\u5982\uff0c\u60a8\u521b\u5efa\u4e86\u4e00\u4e2a\u80fd\u591f\u5b9e\u73b0X\u6027\u80fd\u7684\u7b97\u6cd5\u3002</p> <p>\u7136\u540e\u4f60\u7684\u670b\u53cb\u8bd5\u7740\u9a8c\u8bc1\u4f60\u662f\u5426\u75af\u4e86\u3002</p> <p>\u4ed6\u4eec\u8be5\u5982\u4f55\u505a\u5230\u8fd9\u4e00\u70b9\u5462\uff1f</p> <p>\u8fd9\u5c31\u662f\u53ef\u590d\u73b0\u6027\u7684\u4f5c\u7528\u3002</p> <p>\u6362\u53e5\u8bdd\u8bf4\uff0c\u60a8\u662f\u5426\u53ef\u4ee5\u5728\u60a8\u7684\u8ba1\u7b97\u673a\u4e0a\u8fd0\u884c\u76f8\u540c\u7684\u4ee3\u7801\uff0c\u5f97\u5230\u4e0e\u6211\u5728\u6211\u7684\u8ba1\u7b97\u673a\u4e0a\u5f97\u5230\u7684\u76f8\u540c\uff08\u6216\u975e\u5e38\u76f8\u4f3c\uff09\u7684\u7ed3\u679c\uff1f</p> <p>\u8ba9\u6211\u4eec\u770b\u4e00\u4e2aPyTorch\u4e2d\u7684\u7b80\u5355\u53ef\u590d\u73b0\u6027\u793a\u4f8b\u3002</p> <p>\u9996\u5148\uff0c\u6211\u4eec\u5c06\u521b\u5efa\u4e24\u4e2a\u968f\u673a\u5f20\u91cf\uff0c\u56e0\u4e3a\u5b83\u4eec\u662f\u968f\u673a\u7684\uff0c\u60a8\u671f\u671b\u5b83\u4eec\u662f\u4e0d\u540c\u7684\uff0c\u5bf9\u5417\uff1f</p> <pre><code>import torch\n\n# \u521b\u5efa\u4e24\u4e2a\u968f\u673a\u5f20\u91cf\nrandom_tensor_A = torch.rand(3, 4)\nrandom_tensor_B = torch.rand(3, 4)\n\nprint(f\"\u5f20\u91cf A:\\n{random_tensor_A}\\n\")\nprint(f\"\u5f20\u91cf B:\\n{random_tensor_B}\\n\")\nprint(f\"\u5f20\u91cf A \u662f\u5426\u7b49\u4e8e\u5f20\u91cf B\uff1f\uff08\u4efb\u4f55\u5730\u65b9\uff09\")\nrandom_tensor_A == random_tensor_B\n</code></pre> <pre><code>\u5f20\u91cf A:\ntensor([[0.8016, 0.3649, 0.6286, 0.9663],\n        [0.7687, 0.4566, 0.5745, 0.9200],\n        [0.3230, 0.8613, 0.0919, 0.3102]])\n\n\u5f20\u91cf B:\ntensor([[0.9536, 0.6002, 0.0351, 0.6826],\n        [0.3743, 0.5220, 0.1336, 0.9666],\n        [0.9754, 0.8474, 0.8988, 0.1105]])\n\n\u5f20\u91cf A \u662f\u5426\u7b49\u4e8e\u5f20\u91cf B\uff1f\uff08\u4efb\u4f55\u5730\u65b9\uff09\ntensor([[False, False, False, False],\n        [False, False, False, False],\n        [False, False, False, False]])\n</code></pre> <p>\u6b63\u5982\u60a8\u53ef\u80fd\u5df2\u7ecf\u9884\u6599\u5230\u7684\u90a3\u6837\uff0c\u8fd9\u4e24\u4e2a\u5f20\u91cf\u5177\u6709\u4e0d\u540c\u7684\u503c\u3002</p> <p>\u4f46\u662f\u5982\u679c\u60a8\u60f3\u8981\u521b\u5efa\u4e24\u4e2a\u5177\u6709\u76f8\u540c\u503c\u7684\u968f\u673a\u5f20\u91cf\u5462\uff1f</p> <p>\u4e5f\u5c31\u662f\u8bf4\uff0c\u8fd9\u4e9b\u5f20\u91cf\u4ecd\u7136\u5305\u542b\u968f\u673a\u503c\uff0c\u4f46\u5b83\u4eec\u7684\u5473\u9053\u662f\u76f8\u540c\u7684\u3002</p> <p>\u8fd9\u5c31\u662f<code>torch.manual_seed(seed)</code>\u53d1\u6325\u4f5c\u7528\u7684\u5730\u65b9\uff0c\u5176\u4e2d<code>seed</code>\u662f\u4e00\u4e2a\u6574\u6570\uff08\u6bd4\u5982<code>42</code>\uff0c\u4f46\u53ef\u4ee5\u662f\u4efb\u4f55\u503c\uff09\uff0c\u5b83\u4e3a\u968f\u673a\u6027\u63d0\u4f9b\u4e86\u98ce\u5473\u3002</p> <p>\u8ba9\u6211\u4eec\u5c1d\u8bd5\u4e00\u4e0b\uff0c\u901a\u8fc7\u521b\u5efa\u4e00\u4e9b\u66f4\u591a\u7684\u6709\u98ce\u5473\u7684\u968f\u673a\u5f20\u91cf\u6765\u6d4b\u8bd5\u4e00\u4e0b\u3002</p> <pre><code>import torch\nimport random\n\n# # \u8bbe\u7f6e\u968f\u673a\u79cd\u5b50\nRANDOM_SEED = 42 # \u5c1d\u8bd5\u66f4\u6539\u6b64\u503c\u4ee5\u67e5\u770b\u4e0b\u9762\u7684\u6570\u5b57\u4f1a\u53d1\u751f\u4ec0\u4e48\u53d8\u5316\ntorch.manual_seed(seed=RANDOM_SEED)\nrandom_tensor_C = torch.rand(3, 4)\n\n# \u6bcf\u6b21\u8c03\u7528\u65b0\u7684rand()\u65f6\u90fd\u5fc5\u987b\u8bbe\u7f6e\u79cd\u5b50\n# \u5982\u679c\u4e0d\u8fd9\u6837\u505a\uff0ctensor_D\u5c06\u4e0etensor_C\u4e0d\u540c\ntorch.random.manual_seed(seed=RANDOM_SEED) # \u5c1d\u8bd5\u6ce8\u91ca\u6389\u8fd9\u884c\u4ee3\u7801\uff0c\u770b\u770b\u4f1a\u53d1\u751f\u4ec0\u4e48\nrandom_tensor_D = torch.rand(3, 4)\n\nprint(f\"\u5f20\u91cf C:\\n{random_tensor_C}\\n\")\nprint(f\"\u5f20\u91cf D:\\n{random_tensor_D}\\n\")\nprint(f\"\u5f20\u91cf C \u662f\u5426\u7b49\u4e8e\u5f20\u91cf D\uff1f\uff08\u4efb\u4f55\u5730\u65b9\uff09\")\nrandom_tensor_C == random_tensor_D\n</code></pre> <pre><code>\u5f20\u91cf C:\ntensor([[0.8823, 0.9150, 0.3829, 0.9593],\n        [0.3904, 0.6009, 0.2566, 0.7936],\n        [0.9408, 0.1332, 0.9346, 0.5936]])\n\n\u5f20\u91cf D:\ntensor([[0.8823, 0.9150, 0.3829, 0.9593],\n        [0.3904, 0.6009, 0.2566, 0.7936],\n        [0.9408, 0.1332, 0.9346, 0.5936]])\n\n\u5f20\u91cf C \u662f\u5426\u7b49\u4e8e\u5f20\u91cf D\uff1f\uff08\u4efb\u4f55\u5730\u65b9\uff09\ntensor([[True, True, True, True],\n        [True, True, True, True],\n        [True, True, True, True]])\n</code></pre> <p>\u5f88\u597d\uff01</p> <p>\u770b\u8d77\u6765\u8bbe\u7f6e\u79cd\u5b50\u8d77\u4f5c\u7528\u4e86\u3002</p> <p>\u8d44\u6e90: \u6211\u4eec\u521a\u521a\u8ba8\u8bba\u7684\u53ea\u662fPyTorch\u4e2d\u53ef\u590d\u73b0\u6027\u7684\u51b0\u5c71\u4e00\u89d2\u3002\u8981\u4e86\u89e3\u66f4\u591a\u6709\u5173\u53ef\u590d\u73b0\u6027\u548c\u968f\u673a\u79cd\u5b50\u7684\u4fe1\u606f\uff0c\u53ef\u4ee5\u67e5\u770b\u4ee5\u4e0b\u8d44\u6e90\uff1a</p> <ul> <li>PyTorch\u53ef\u590d\u73b0\u6027\u6587\u6863\uff08\u53ef\u4ee5\u82b110\u5206\u949f\u65f6\u95f4\u9605\u8bfb\u4e00\u4e0b\uff0c\u5373\u4f7f\u73b0\u5728\u4e0d\u7406\u89e3\uff0c\u4e86\u89e3\u5b83\u4e5f\u5f88\u91cd\u8981\uff09\u3002</li> <li>\u7ef4\u57fa\u767e\u79d1\u4e0a\u7684\u968f\u673a\u79cd\u5b50\u9875\u9762\uff08\u8fd9\u5c06\u4e3a\u968f\u673a\u79cd\u5b50\u548c\u4f2a\u968f\u673a\u6027\u63d0\u4f9b\u5f88\u597d\u7684\u6982\u8ff0\uff09\u3002</li> </ul>"},{"location":"tutorials/00_pytorch_fundamentals/#gpu","title":"\u5728GPU\u4e0a\u8fd0\u884c\u5f20\u91cf\uff08\u4ee5\u53ca\u8fdb\u884c\u66f4\u5feb\u7684\u8ba1\u7b97\uff09","text":"<p>\u6df1\u5ea6\u5b66\u4e60\u7b97\u6cd5\u9700\u8981\u5927\u91cf\u7684\u6570\u503c\u8fd0\u7b97\u3002</p> <p>\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u8fd9\u4e9b\u8fd0\u7b97\u901a\u5e38\u5728CPU\uff08\u4e2d\u592e\u5904\u7406\u5355\u5143\uff09\u4e0a\u6267\u884c\u3002</p> <p>\u7136\u800c\uff0c\u8fd8\u6709\u4e00\u79cd\u5e38\u89c1\u7684\u786c\u4ef6\u79f0\u4e3aGPU\uff08\u56fe\u5f62\u5904\u7406\u5355\u5143\uff09\uff0c\u5b83\u901a\u5e38\u6bd4CPU\u66f4\u5feb\u5730\u6267\u884c\u795e\u7ecf\u7f51\u7edc\u9700\u8981\u7684\u7279\u5b9a\u7c7b\u578b\u7684\u64cd\u4f5c\uff08\u77e9\u9635\u4e58\u6cd5\uff09\u3002</p> <p>\u4f60\u7684\u8ba1\u7b97\u673a\u53ef\u80fd\u6709\u4e00\u4e2a\u3002</p> <p>\u5982\u679c\u6709\u7684\u8bdd\uff0c\u4f60\u5e94\u8be5\u5c3d\u91cf\u5229\u7528\u5b83\u6765\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\uff0c\u56e0\u4e3a\u5f88\u53ef\u80fd\u4f1a\u663e\u8457\u52a0\u5feb\u8bad\u7ec3\u65f6\u95f4\u3002</p> <p>\u6709\u51e0\u79cd\u65b9\u6cd5\u53ef\u4ee5\u9996\u5148\u83b7\u53d6GPU\u7684\u8bbf\u95ee\u6743\u9650\uff0c\u7136\u540e\u8ba9PyTorch\u4f7f\u7528GPU\u3002</p> <p>\u6ce8\u610f\uff1a \u201cGPU\u201d\u6307\u7684\u662f\u542f\u7528\u4e86CUDA\u7684Nvidia GPU\uff08CUDA\u662f\u4e00\u79cd\u8ba1\u7b97\u5e73\u53f0\u548cAPI\uff0c\u5e2e\u52a9GPU\u7528\u4e8e\u901a\u7528\u8ba1\u7b97\u800c\u4e0d\u4ec5\u4ec5\u662f\u56fe\u5f62\uff09\u3002</p>"},{"location":"tutorials/00_pytorch_fundamentals/#1-gpu","title":"1. \u83b7\u53d6GPU","text":"<p>\u60a8\u53ef\u80fd\u5df2\u7ecf\u77e5\u9053\u6211\u8bf4GPU\u65f6\u53d1\u751f\u4e86\u4ec0\u4e48\u3002\u4f46\u5982\u679c\u4e0d\u77e5\u9053\uff0c\u6709\u51e0\u79cd\u65b9\u6cd5\u53ef\u4ee5\u83b7\u53d6GPU\u7684\u8bbf\u95ee\u6743\u9650\u3002</p> \u65b9\u6cd5 \u8bbe\u7f6e\u96be\u5ea6 \u4f18\u70b9 \u7f3a\u70b9 \u8bbe\u7f6e\u65b9\u6cd5 Google Colab \u7b80\u5355 \u514d\u8d39\u4f7f\u7528\uff0c\u51e0\u4e4e\u4e0d\u9700\u8981\u4efb\u4f55\u8bbe\u7f6e\uff0c\u53ef\u4ee5\u4e0e\u4ed6\u4eba\u5171\u4eab\u5de5\u4f5c\uff0c\u53ea\u9700\u4e00\u4e2a\u94fe\u63a5 \u4e0d\u4fdd\u5b58\u60a8\u7684\u6570\u636e\u8f93\u51fa\uff0c\u8ba1\u7b97\u80fd\u529b\u6709\u9650\uff0c\u53ef\u80fd\u4f1a\u8d85\u65f6 \u6309\u7167Google Colab\u6307\u5357\u64cd\u4f5c \u4f7f\u7528\u60a8\u81ea\u5df1\u7684\u8ba1\u7b97\u673a \u4e2d\u7b49 \u5728\u60a8\u81ea\u5df1\u7684\u673a\u5668\u4e0a\u672c\u5730\u8fd0\u884c\u6240\u6709\u5185\u5bb9 GPU\u4e0d\u662f\u514d\u8d39\u7684\uff0c\u9700\u8981\u9884\u4ed8\u8d39\u7528 \u6309\u7167PyTorch\u5b89\u88c5\u6307\u5357\u64cd\u4f5c \u4e91\u8ba1\u7b97\uff08AWS\u3001GCP\u3001Azure\uff09 \u4e2d\u7b49-\u56f0\u96be \u5c0f\u989d\u9884\u4ed8\u8d39\u7528\uff0c\u51e0\u4e4e\u65e0\u9650\u7684\u8ba1\u7b97\u8d44\u6e90 \u5982\u679c\u6301\u7eed\u8fd0\u884c\uff0c\u6210\u672c\u53ef\u80fd\u8f83\u9ad8\uff0c\u8bbe\u7f6e\u6b63\u786e\u9700\u8981\u4e00\u4e9b\u65f6\u95f4 \u6309\u7167PyTorch\u5b89\u88c5\u6307\u5357\u64cd\u4f5c <p>\u8fd8\u6709\u66f4\u591a\u4f7f\u7528GPU\u7684\u9009\u9879\uff0c\u4f46\u4e0a\u9762\u7684\u4e09\u79cd\u73b0\u5728\u5c31\u8db3\u591f\u4e86\u3002</p> <p>\u4e2a\u4eba\u800c\u8a00\uff0c\u5728\u5c0f\u89c4\u6a21\u5b9e\u9a8c\uff08\u4ee5\u53ca\u521b\u5efa\u672c\u8bfe\u7a0b\u65f6\uff09\u65f6\u4f7f\u7528Google Colab\u548c\u81ea\u5df1\u7684\u4e2a\u4eba\u8ba1\u7b97\u673a\u7684\u7ec4\u5408\uff0c\u9700\u8981\u66f4\u591a\u8ba1\u7b97\u8d44\u6e90\u65f6\u5219\u4f7f\u7528\u4e91\u8d44\u6e90\u3002</p> <p>\u8d44\u6e90\uff1a \u5982\u679c\u60a8\u60f3\u8d2d\u4e70\u81ea\u5df1\u7684GPU\uff0c\u4f46\u4e0d\u786e\u5b9a\u5e94\u8be5\u8d2d\u4e70\u54ea\u79cd\u578b\u53f7\uff0cTim Dettmers\u6709\u4e00\u4efd\u51fa\u8272\u7684\u6307\u5357\u3002</p> <p>\u8981\u68c0\u67e5\u662f\u5426\u53ef\u4ee5\u8bbf\u95eeNvidia GPU\uff0c\u8bf7\u8fd0\u884c<code>!nvidia-smi</code>\uff0c\u5176\u4e2d<code>!</code>\uff08\u4e5f\u79f0\u4e3abang\uff09\u8868\u793a\u201c\u5728\u547d\u4ee4\u884c\u4e0a\u8fd0\u884c\u6b64\u547d\u4ee4\u201d\u3002</p> <pre><code>!nvidia-smi\n</code></pre> <pre><code>Sat Jan 21 08:34:23 2023       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 515.48.07    Driver Version: 515.48.07    CUDA Version: 11.7     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  NVIDIA TITAN RTX    On   | 00000000:01:00.0 Off |                  N/A |\n| 40%   30C    P8     7W / 280W |    177MiB / 24576MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|    0   N/A  N/A      1061      G   /usr/lib/xorg/Xorg                 53MiB |\n|    0   N/A  N/A   2671131      G   /usr/lib/xorg/Xorg                 97MiB |\n|    0   N/A  N/A   2671256      G   /usr/bin/gnome-shell                9MiB |\n+-----------------------------------------------------------------------------+\n</code></pre> <p>\u5982\u679c\u60a8\u6ca1\u6709Nvidia GPU\u53ef\u7528\uff0c\u4e0a\u9762\u7684\u8f93\u51fa\u5c06\u663e\u793a\u7c7b\u4f3c\u4e8e\u4ee5\u4e0b\u5185\u5bb9\uff1a</p> <pre><code>NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n</code></pre> <p>\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u8fd4\u56de\u5e76\u6309\u7167\u5b89\u88c5\u6b65\u9aa4\u64cd\u4f5c\u3002</p> <p>\u5982\u679c\u60a8\u6709GPU\uff0c\u5219\u4e0a\u8ff0\u884c\u5c06\u663e\u793a\u7c7b\u4f3c\u4e8e\u4ee5\u4e0b\u5185\u5bb9\uff1a</p> <pre><code>Wed Jan 19 22:09:08 2022       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   35C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage     \n\n |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n</code></pre>"},{"location":"tutorials/00_pytorch_fundamentals/#2-pytorchgpu","title":"2. \u8ba9PyTorch\u5728GPU\u4e0a\u8fd0\u884c","text":"<p>\u4e00\u65e6\u60a8\u51c6\u5907\u597d\u8bbf\u95eeGPU\uff0c\u4e0b\u4e00\u6b65\u5c31\u662f\u8ba9PyTorch\u7528\u4e8e\u5b58\u50a8\u6570\u636e\uff08\u5f20\u91cf\uff09\u548c\u5728\u6570\u636e\u4e0a\u8fdb\u884c\u8ba1\u7b97\uff08\u5bf9\u5f20\u91cf\u6267\u884c\u64cd\u4f5c\uff09\u3002</p> <p>\u4e3a\u6b64\uff0c\u60a8\u53ef\u4ee5\u4f7f\u7528<code>torch.cuda</code>\u5305\u3002</p> <p>\u4e0d\u8981\u53ea\u662f\u8c08\u8bba\u5b83\uff0c\u8ba9\u6211\u4eec\u5c1d\u8bd5\u4e00\u4e0b\u3002</p> <p>\u60a8\u53ef\u4ee5\u4f7f\u7528<code>torch.cuda.is_available()</code>\u6765\u6d4b\u8bd5PyTorch\u662f\u5426\u53ef\u4ee5\u8bbf\u95eeGPU\u3002</p> <pre><code># \u68c0\u67e5\u662f\u5426\u6709GPU\nimport torch\ntorch.cuda.is_available()\n</code></pre> <p>\u5982\u679c\u4e0a\u9762\u8f93\u51fa<code>True</code>\uff0c\u8868\u793aPyTorch\u53ef\u4ee5\u770b\u5230\u5e76\u4f7f\u7528GPU\uff0c\u5982\u679c\u8f93\u51fa<code>False</code>\uff0c\u8868\u793a\u5b83\u65e0\u6cd5\u770b\u5230GPU\uff0c\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u60a8\u9700\u8981\u8fd4\u56de\u5b89\u88c5\u6b65\u9aa4\u3002</p> <p>\u73b0\u5728\uff0c\u5047\u8bbe\u60a8\u60f3\u8bbe\u7f6e\u60a8\u7684\u4ee3\u7801\uff0c\u4ee5\u4fbf\u5728CPU\u4e0a\u8fd0\u884c\u6216\u5728GPU\u53ef\u7528\u65f6\u8fd0\u884c\u3002</p> <p>\u8fd9\u6837\uff0c\u5982\u679c\u60a8\u6216\u5176\u4ed6\u4eba\u51b3\u5b9a\u8fd0\u884c\u60a8\u7684\u4ee3\u7801\uff0c\u65e0\u8bba\u4f7f\u7528\u7684\u8ba1\u7b97\u8bbe\u5907\u662f\u4ec0\u4e48\uff0c\u5b83\u90fd\u53ef\u4ee5\u6b63\u5e38\u5de5\u4f5c\u3002</p> <p>\u8ba9\u6211\u4eec\u521b\u5efa\u4e00\u4e2a<code>device</code>\u53d8\u91cf\u6765\u5b58\u50a8\u53ef\u7528\u7684\u8bbe\u5907\u7c7b\u578b\u3002</p> <pre><code># \u8bbe\u7f6e\u8bbe\u5907\u7c7b\u578b\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice\n</code></pre> <p>\u5982\u679c\u4e0a\u9762\u8f93\u51fa\u4e86<code>\"cuda\"</code>\uff0c\u8fd9\u610f\u5473\u7740\u6211\u4eec\u53ef\u4ee5\u8bbe\u7f6e\u6240\u6709PyTorch\u4ee3\u7801\u6765\u4f7f\u7528\u53ef\u7528\u7684CUDA\u8bbe\u5907\uff08GPU\uff09\uff0c\u5982\u679c\u8f93\u51fa\u4e86<code>\"cpu\"</code>\uff0c\u6211\u4eec\u7684PyTorch\u4ee3\u7801\u5c06\u7ee7\u7eed\u4f7f\u7528CPU\u3002</p> <p>\u6ce8\u610f\uff1a \u5728PyTorch\u4e2d\uff0c\u6700\u4f73\u5b9e\u8df5\u662f\u7f16\u5199\u8bbe\u5907\u4e0d\u53ef\u77e5\u7684\u4ee3\u7801\u3002\u8fd9\u610f\u5473\u7740\u4ee3\u7801\u5c06\u5728CPU\u4e0a\u8fd0\u884c\uff08\u59cb\u7ec8\u53ef\u7528\uff09\u6216GPU\u4e0a\u8fd0\u884c\uff08\u5982\u679c\u53ef\u7528\uff09\u3002</p> <p>\u5982\u679c\u8981\u8fdb\u884c\u66f4\u5feb\u7684\u8ba1\u7b97\uff0c\u53ef\u4ee5\u4f7f\u7528GPU\uff0c\u4f46\u5982\u679c\u8981\u8fdb\u884c\u66f4\u5feb\u7684\u8ba1\u7b97\uff0c\u53ef\u4ee5\u4f7f\u7528\u591a\u4e2aGPU\u3002</p> <p>\u60a8\u53ef\u4ee5\u4f7f\u7528<code>torch.cuda.device_count()</code>\u6765\u8ba1\u7b97PyTorch\u53ef\u4ee5\u8bbf\u95ee\u7684GPU\u6570\u91cf\u3002</p> <pre><code># \u8ba1\u7b97\u8bbe\u5907\u6570\u91cf\ntorch.cuda.device_count()\n</code></pre> <p>\u77e5\u9053PyTorch\u53ef\u4ee5\u8bbf\u95ee\u7684GPU\u6570\u91cf\u5bf9\u4e8e\u5982\u679c\u60a8\u60f3\u5728\u4e00\u4e2aGPU\u4e0a\u8fd0\u884c\u7279\u5b9a\u8fdb\u7a0b\u5e76\u5728\u53e6\u4e00\u4e2aGPU\u4e0a\u8fd0\u884c\u53e6\u4e00\u4e2a\u8fdb\u7a0b\u662f\u6709\u5e2e\u52a9\u7684\uff08PyTorch\u8fd8\u5177\u6709\u8ba9\u60a8\u5728\u6240\u6709GPU\u4e0a\u8fd0\u884c\u8fdb\u7a0b\u7684\u529f\u80fd\uff09\u3002</p>"},{"location":"tutorials/00_pytorch_fundamentals/#3-gpu","title":"3. \u5c06\u5f20\u91cf\uff08\u6216\u6a21\u578b\uff09\u653e\u5728 GPU \u4e0a","text":"<p>\u60a8\u53ef\u4ee5\u901a\u8fc7\u8c03\u7528 <code>to(device)</code> \u5c06\u5f20\u91cf\uff08\u6216\u6a21\u578b\uff09\u653e\u5728\u7279\u5b9a\u8bbe\u5907\u4e0a\u3002\u5176\u4e2d <code>device</code> \u662f\u60a8\u5e0c\u671b\u5f20\u91cf\uff08\u6216\u6a21\u578b\uff09\u653e\u7f6e\u7684\u76ee\u6807\u8bbe\u5907\u3002</p> <p>\u4e3a\u4ec0\u4e48\u8981\u8fd9\u6837\u505a\uff1f</p> <p>GPU \u6bd4 CPU \u63d0\u4f9b\u66f4\u5feb\u7684\u6570\u503c\u8ba1\u7b97\u901f\u5ea6\uff0c\u5982\u679c\u6ca1\u6709\u53ef\u7528\u7684 GPU\uff0c\u7531\u4e8e\u6211\u4eec\u7684\u8bbe\u5907\u65e0\u5173\u4ee3\u7801\uff08\u89c1\u4e0a\u6587\uff09\uff0c\u5b83\u5c06\u5728 CPU \u4e0a\u8fd0\u884c\u3002</p> <p>\u6ce8\u610f\uff1a \u4f7f\u7528 <code>to(device)</code> \u5c06\u5f20\u91cf\u653e\u5728 GPU \u4e0a\uff08\u4f8b\u5982 <code>some_tensor.to(device)</code>\uff09\u4f1a\u8fd4\u56de\u8be5\u5f20\u91cf\u7684\u526f\u672c\uff0c\u5373\u76f8\u540c\u7684\u5f20\u91cf\u5c06\u540c\u65f6\u5b58\u5728\u4e8e CPU \u548c GPU \u4e0a\u3002\u8981\u8986\u76d6\u5f20\u91cf\uff0c\u8bf7\u91cd\u65b0\u5206\u914d\u5b83\u4eec\uff1a</p> <p><code>some_tensor = some_tensor.to(device)</code></p> <p>\u8ba9\u6211\u4eec\u5c1d\u8bd5\u521b\u5efa\u4e00\u4e2a\u5f20\u91cf\u5e76\u5c06\u5176\u653e\u5728 GPU \u4e0a\uff08\u5982\u679c\u53ef\u7528\uff09\u3002</p> <pre><code># \u521b\u5efa\u5f20\u91cf\uff08\u9ed8\u8ba4\u5728 CPU \u4e0a\uff09\ntensor = torch.tensor([1, 2, 3])\n\n# \u5f20\u91cf\u4e0d\u5728 GPU \u4e0a\nprint(tensor, tensor.device)\n\n# \u5c06\u5f20\u91cf\u79fb\u52a8\u5230 GPU\uff08\u5982\u679c\u53ef\u7528\uff09\ntensor_on_gpu = tensor.to(device)\ntensor_on_gpu\n</code></pre> <p>\u5982\u679c\u60a8\u6709\u53ef\u7528\u7684 GPU\uff0c\u5219\u4e0a\u8ff0\u4ee3\u7801\u5c06\u8f93\u51fa\u7c7b\u4f3c\u4ee5\u4e0b\u5185\u5bb9\uff1a</p> <pre><code>tensor([1, 2, 3]) cpu\ntensor([1, 2, 3], device='cuda:0')\n</code></pre> <p>\u8bf7\u6ce8\u610f\uff0c\u7b2c\u4e8c\u4e2a\u5f20\u91cf\u5177\u6709 <code>device='cuda:0'</code>\uff0c\u8fd9\u610f\u5473\u7740\u5b83\u5b58\u50a8\u5728\u53ef\u7528\u7684\u7b2c 0 \u4e2a GPU \u4e0a\uff08GPU \u662f\u4ece 0 \u5f00\u59cb\u7d22\u5f15\u7684\uff0c\u5982\u679c\u6709\u4e24\u4e2a\u53ef\u7528\u7684 GPU\uff0c\u5219\u5206\u522b\u662f <code>'cuda:0'</code> \u548c <code>'cuda:1'</code>\uff0c\u4f9d\u6b64\u7c7b\u63a8\uff0c\u76f4\u5230 <code>'cuda:n'</code>\uff09\u3002</p>"},{"location":"tutorials/00_pytorch_fundamentals/#4-cpu","title":"4. \u5c06\u5f20\u91cf\u79fb\u56de CPU","text":"<p>\u5982\u679c\u6211\u4eec\u60f3\u5c06\u5f20\u91cf\u79fb\u56de CPU \u600e\u4e48\u529e\uff1f</p> <p>\u4f8b\u5982\uff0c\u5982\u679c\u8981\u4f7f\u7528 NumPy \u4e0e\u5f20\u91cf\u4ea4\u4e92\uff0c\u60a8\u5c06\u9700\u8981\u8fd9\u6837\u505a\uff08\u56e0\u4e3a NumPy \u4e0d\u4f7f\u7528 GPU\uff09\u3002</p> <p>\u8ba9\u6211\u4eec\u5c1d\u8bd5\u5728 <code>tensor_on_gpu</code> \u4e0a\u4f7f\u7528 <code>torch.Tensor.numpy()</code> \u65b9\u6cd5\u3002</p> <pre><code># \u5982\u679c\u5f20\u91cf\u5728 GPU \u4e0a\uff0c\u5219\u65e0\u6cd5\u5c06\u5176\u8f6c\u6362\u4e3a NumPy\uff08\u5c06\u4f1a\u51fa\u9519\uff09\ntensor_on_gpu.numpy()\n</code></pre> <p>\u8fd9\u5c06\u5f15\u53d1\u9519\u8bef\uff0c\u5982\u4e0b\u6240\u793a\uff1a</p> <pre><code>TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n</code></pre> <p>\u76f8\u53cd\uff0c\u8981\u5c06\u5f20\u91cf\u8f6c\u56de CPU \u5e76\u4e0e NumPy \u4e00\u8d77\u4f7f\u7528\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 <code>Tensor.cpu()</code>\u3002</p> <p>\u8fd9\u4f1a\u5c06\u5f20\u91cf\u590d\u5236\u5230 CPU \u5185\u5b58\u4e2d\uff0c\u4ee5\u4fbf\u4e0e CPU \u4e00\u8d77\u4f7f\u7528\u3002</p> <pre><code># \u76f8\u53cd\uff0c\u5c06\u5f20\u91cf\u590d\u5236\u56de CPU\ntensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\ntensor_back_on_cpu\n</code></pre> <p>\u4e0a\u8ff0\u4ee3\u7801\u8fd4\u56de GPU \u5f20\u91cf\u7684\u526f\u672c\uff0c\u5b58\u50a8\u5728 CPU \u5185\u5b58\u4e2d\uff0c\u56e0\u6b64\u539f\u59cb\u5f20\u91cf\u4ecd\u5728 GPU \u4e0a\u3002</p> <pre><code>tensor_on_gpu\n</code></pre>"},{"location":"tutorials/00_pytorch_fundamentals/#_18","title":"\u7ec3\u4e60","text":"<p>\u6240\u6709\u7ec3\u4e60\u90fd\u4fa7\u91cd\u4e8e\u7ec3\u4e60\u4e0a\u8ff0\u4ee3\u7801\u3002</p> <p>\u60a8\u5e94\u8be5\u80fd\u591f\u901a\u8fc7\u53c2\u8003\u6bcf\u4e2a\u90e8\u5206\u6216\u6309\u7167\u94fe\u63a5\u7684\u8d44\u6e90\u5b8c\u6210\u5b83\u4eec\u3002</p> <p>\u8d44\u6e90\uff1a</p> <ul> <li>00 \u7ec3\u4e60\u6a21\u677f\u7b14\u8bb0\u672c\u3002</li> <li> <p>00 \u7ec3\u4e60\u793a\u4f8b\u89e3\u7b54\u7b14\u8bb0\u672c\uff08\u5728\u67e5\u770b\u6b64\u7b14\u8bb0\u672c\u4e4b\u524d\u5c1d\u8bd5\u7ec3\u4e60\uff09\u3002</p> </li> <li> <p>\u9605\u8bfb\u6587\u6863 - \u6df1\u5ea6\u5b66\u4e60\uff08\u4ee5\u53ca\u4e00\u822c\u7f16\u7a0b\u5b66\u4e60\uff09\u7684\u91cd\u8981\u7ec4\u6210\u90e8\u5206\u4e4b\u4e00\u662f\u719f\u6089\u60a8\u6b63\u5728\u4f7f\u7528\u7684\u7279\u5b9a\u6846\u67b6\u7684\u6587\u6863\u3002\u6211\u4eec\u5c06\u5728\u672c\u8bfe\u7a0b\u7684\u5176\u4f59\u90e8\u5206\u4e2d\u7ecf\u5e38\u4f7f\u7528 PyTorch \u6587\u6863\u3002\u56e0\u6b64\uff0c\u6211\u5efa\u8bae\u82b1\u8d39 10 \u5206\u949f\u9605\u8bfb\u4ee5\u4e0b\u5185\u5bb9\uff08\u5982\u679c\u60a8\u6682\u65f6\u4e0d\u7406\u89e3\u67d0\u4e9b\u5185\u5bb9\uff0c\u4e5f\u6ca1\u5173\u7cfb\uff0c\u91cd\u70b9\u4e0d\u662f\u5b8c\u5168\u7406\u89e3\uff0c\u800c\u662f\u4e86\u89e3\uff09\u3002\u67e5\u770b <code>torch.Tensor</code> \u548c <code>torch.cuda</code> \u7684\u6587\u6863\u3002</p> </li> <li>\u521b\u5efa\u4e00\u4e2a\u5f62\u72b6\u4e3a <code>(7, 7)</code> \u7684\u968f\u673a\u5f20\u91cf\u3002</li> <li>\u5bf9\u6765\u81ea\u7b2c 2 \u6b65\u7684\u5f20\u91cf\u4e0e\u53e6\u4e00\u4e2a\u5f62\u72b6\u4e3a <code>(1, 7)</code> \u7684\u968f\u673a\u5f20\u91cf\u6267\u884c\u77e9\u9635\u4e58\u6cd5\uff08\u63d0\u793a\uff1a\u60a8\u53ef\u80fd\u9700\u8981\u8f6c\u7f6e\u7b2c\u4e8c\u4e2a\u5f20\u91cf\uff09\u3002</li> <li>\u5c06\u968f\u673a\u79cd\u5b50\u8bbe\u7f6e\u4e3a <code>0</code>\uff0c\u7136\u540e\u518d\u6b21\u6267\u884c\u6b65\u9aa4 2 \u548c 3\u3002</li> <li>\u8c08\u5230\u968f\u673a\u79cd\u5b50\uff0c\u6211\u4eec\u770b\u5230\u5982\u4f55\u4f7f\u7528 <code>torch.manual_seed()</code> \u8bbe\u7f6e\u5b83\uff0c\u4f46\u662f\u5426\u6709 GPU \u7b49\u6548\u9879\uff1f\uff08\u63d0\u793a\uff1a\u60a8\u9700\u8981\u67e5\u770b <code>torch.cuda</code> \u7684\u6587\u6863\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff09\u3002\u5982\u679c\u6709\u7684\u8bdd\uff0c\u5c06 GPU \u968f\u673a\u79cd\u5b50\u8bbe\u7f6e\u4e3a <code>1234</code>\u3002</li> <li>\u521b\u5efa\u4e24\u4e2a\u5f62\u72b6\u4e3a <code>(2, 3)</code> \u7684\u968f\u673a\u5f20\u91cf\uff0c\u5e76\u5c06\u5b83\u4eec\u90fd\u53d1\u9001\u5230 GPU \u4e0a\uff08\u60a8\u9700\u8981\u8bbf\u95ee GPU \u624d\u80fd\u5b8c\u6210\u6b64\u64cd\u4f5c\uff09\u3002\u5728\u521b\u5efa\u5f20\u91cf\u65f6\u8bbe\u7f6e <code>torch.manual_seed(1234)</code>\uff08\u8fd9\u4e0d\u5fc5\u662f GPU \u968f\u673a\u79cd\u5b50\uff09\u3002</li> <li>\u5bf9\u60a8\u5728\u7b2c 6 \u6b65\u4e2d\u521b\u5efa\u7684\u5f20\u91cf\u6267\u884c\u77e9\u9635\u4e58\u6cd5\uff08\u518d\u6b21\uff0c\u60a8\u53ef\u80fd\u9700\u8981\u8c03\u6574\u5176\u4e2d\u4e00\u4e2a\u5f20\u91cf\u7684\u5f62\u72b6\uff09\u3002</li> <li>\u627e\u51fa\u7b2c 7 \u6b65\u7684\u8f93\u51fa\u7684\u6700\u5927\u503c\u548c\u6700\u5c0f\u503c\u3002</li> <li>\u627e\u51fa\u7b2c 7 \u6b65\u7684\u8f93\u51fa\u7684\u6700\u5927\u7d22\u5f15\u503c\u548c\u6700\u5c0f\u7d22\u5f15\u503c\u3002</li> <li>\u521b\u5efa\u4e00\u4e2a\u5f62\u72b6\u4e3a <code>(1, 1, 1, 10)</code> \u7684\u968f\u673a\u5f20\u91cf\uff0c\u7136\u540e\u521b\u5efa\u4e00\u4e2a\u65b0\u5f20\u91cf\uff0c\u5c06\u6240\u6709 <code>1</code> \u7ef4\u5ea6\u79fb\u9664\uff0c\u4ee5\u5f97\u5230\u5f62\u72b6\u4e3a <code>(10)</code> \u7684\u5f20\u91cf\u3002\u5728\u521b\u5efa\u65f6\u5c06\u79cd\u5b50\u8bbe\u7f6e\u4e3a <code>7</code>\uff0c\u5e76\u6253\u5370\u51fa\u7b2c\u4e00\u4e2a\u5f20\u91cf\u53ca\u5176\u5f62\u72b6\u4ee5\u53ca\u7b2c\u4e8c\u4e2a\u5f20\u91cf\u53ca\u5176\u5f62\u72b6\u3002</li> </ul>"},{"location":"tutorials/00_pytorch_fundamentals/#_19","title":"\u8865\u5145","text":"<ul> <li>\u82b1\u8d39 1 \u5c0f\u65f6\u5b66\u4e60 PyTorch \u57fa\u7840\u6559\u7a0b\uff08\u6211\u5efa\u8bae\u67e5\u770b \u5feb\u901f\u5165\u95e8 \u548c \u5f20\u91cf \u90e8\u5206\uff09\u3002</li> <li>\u4e86\u89e3\u5f20\u91cf\u5982\u4f55\u8868\u793a\u6570\u636e\uff0c\u89c2\u770b\u6b64\u89c6\u9891\uff1a\u4ec0\u4e48\u662f\u5f20\u91cf\uff1f\u3002</li> </ul>"}]}